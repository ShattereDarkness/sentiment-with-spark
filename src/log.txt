21/12/04 17:28:19 WARN Utils: Your hostname, pes1ug19cs458-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
21/12/04 17:28:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/12/04 17:28:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/12/04 17:28:21 INFO SparkContext: Running Spark version 3.1.2
21/12/04 17:28:21 INFO ResourceUtils: ==============================================================
21/12/04 17:28:21 INFO ResourceUtils: No custom resources configured for spark.driver.
21/12/04 17:28:21 INFO ResourceUtils: ==============================================================
21/12/04 17:28:21 INFO SparkContext: Submitted application: ScamStreaming
21/12/04 17:28:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/12/04 17:28:21 INFO ResourceProfile: Limiting resource is cpu
21/12/04 17:28:21 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/12/04 17:28:21 INFO SecurityManager: Changing view acls to: pes1ug19cs458
21/12/04 17:28:21 INFO SecurityManager: Changing modify acls to: pes1ug19cs458
21/12/04 17:28:21 INFO SecurityManager: Changing view acls groups to: 
21/12/04 17:28:21 INFO SecurityManager: Changing modify acls groups to: 
21/12/04 17:28:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pes1ug19cs458); groups with view permissions: Set(); users  with modify permissions: Set(pes1ug19cs458); groups with modify permissions: Set()
21/12/04 17:28:21 INFO Utils: Successfully started service 'sparkDriver' on port 33623.
21/12/04 17:28:21 INFO SparkEnv: Registering MapOutputTracker
21/12/04 17:28:21 INFO SparkEnv: Registering BlockManagerMaster
21/12/04 17:28:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/12/04 17:28:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/12/04 17:28:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/12/04 17:28:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-740fd874-86a0-423d-8754-69158679a50a
21/12/04 17:28:22 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/12/04 17:28:22 INFO SparkEnv: Registering OutputCommitCoordinator
21/12/04 17:28:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/12/04 17:28:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.2.15:4040
21/12/04 17:28:22 INFO Executor: Starting executor ID driver on host 10.0.2.15
21/12/04 17:28:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40275.
21/12/04 17:28:23 INFO NettyBlockTransferService: Server created on 10.0.2.15:40275
21/12/04 17:28:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/12/04 17:28:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.2.15, 40275, None)
21/12/04 17:28:23 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.15:40275 with 366.3 MiB RAM, BlockManagerId(driver, 10.0.2.15, 40275, None)
21/12/04 17:28:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.2.15, 40275, None)
21/12/04 17:28:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.2.15, 40275, None)
21/12/04 17:28:24 INFO ReceiverTracker: Starting 1 receivers
21/12/04 17:28:24 INFO ReceiverTracker: ReceiverTracker started
21/12/04 17:28:24 INFO SocketInputDStream: Slide time = 5000 ms
21/12/04 17:28:24 INFO SocketInputDStream: Storage level = Serialized 1x Replicated
21/12/04 17:28:24 INFO SocketInputDStream: Checkpoint interval = null
21/12/04 17:28:24 INFO SocketInputDStream: Remember interval = 5000 ms
21/12/04 17:28:24 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@3e2a38ac
21/12/04 17:28:24 INFO ForEachDStream: Slide time = 5000 ms
21/12/04 17:28:24 INFO ForEachDStream: Storage level = Serialized 1x Replicated
21/12/04 17:28:24 INFO ForEachDStream: Checkpoint interval = null
21/12/04 17:28:24 INFO ForEachDStream: Remember interval = 5000 ms
21/12/04 17:28:24 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@1eb0bfe4
21/12/04 17:28:24 INFO RecurringTimer: Started timer for JobGenerator at time 1638619105000
21/12/04 17:28:24 INFO JobGenerator: Started JobGenerator at 1638619105000 ms
21/12/04 17:28:24 INFO JobScheduler: Started JobScheduler
21/12/04 17:28:24 INFO ReceiverTracker: Receiver 0 started
21/12/04 17:28:24 INFO StreamingContext: StreamingContext started
21/12/04 17:28:24 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:28:24 INFO DAGScheduler: Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)
21/12/04 17:28:24 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:24 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:24 INFO DAGScheduler: Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
21/12/04 17:28:25 INFO JobScheduler: Added jobs for time 1638619105000 ms
21/12/04 17:28:25 INFO JobScheduler: Starting job streaming job 1638619105000 ms.0 from job set of time 1638619105000 ms
21/12/04 17:28:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 81.3 KiB, free 366.2 MiB)
21/12/04 17:28:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:25 INFO DAGScheduler: Job 1 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.005377 s
21/12/04 17:28:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 366.2 MiB)
21/12/04 17:28:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.15:40275 (size: 28.5 KiB, free: 366.3 MiB)
21/12/04 17:28:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:25 INFO JobScheduler: Finished job streaming job 1638619105000 ms.0 from job set of time 1638619105000 ms
21/12/04 17:28:25 INFO JobScheduler: Total delay: 0.349 s for time 1638619105000 ms (execution: 0.271 s)
21/12/04 17:28:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:25 INFO ReceivedBlockTracker: Deleting batches: 
21/12/04 17:28:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
21/12/04 17:28:25 INFO InputInfoTracker: remove old batch metadata: 
21/12/04 17:28:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 5478 bytes) taskResourceAssignments Map()
21/12/04 17:28:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/12/04 17:28:25 INFO RecurringTimer: Started timer for BlockGenerator at time 1638619105800
21/12/04 17:28:25 INFO BlockGenerator: Started BlockGenerator
21/12/04 17:28:25 INFO BlockGenerator: Started block pushing thread
21/12/04 17:28:25 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:28:25 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:28:25 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:28:25 INFO SocketReceiver: Connected to localhost:6100
21/12/04 17:28:25 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:28:25 INFO ReceiverSupervisorImpl: Waiting for receiver to be stopped
21/12/04 17:28:26 INFO MemoryStore: Block input-0-1638619106200 stored as values in memory (estimated size 1881.7 KiB, free 364.4 MiB)
21/12/04 17:28:26 INFO BlockManagerInfo: Added input-0-1638619106200 in memory on 10.0.2.15:40275 (size: 1881.7 KiB, free: 364.4 MiB)
21/12/04 17:28:26 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:28:26 WARN BlockManager: Block input-0-1638619106200 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:28:26 INFO BlockGenerator: Pushed block input-0-1638619106200
21/12/04 17:28:30 INFO JobScheduler: Added jobs for time 1638619110000 ms
21/12/04 17:28:30 INFO JobScheduler: Starting job streaming job 1638619110000 ms.0 from job set of time 1638619110000 ms
21/12/04 17:28:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:30 INFO DAGScheduler: Got job 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:30 INFO DAGScheduler: Final stage: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:30 INFO DAGScheduler: Submitting ResultStage 1 (BlockRDD[2] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1968.0 B, free 364.4 MiB)
21/12/04 17:28:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1210.0 B, free 364.4 MiB)
21/12/04 17:28:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 364.4 MiB)
21/12/04 17:28:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (BlockRDD[2] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
21/12/04 17:28:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/12/04 17:28:30 INFO BlockManager: Found block input-0-1638619106200 locally
21/12/04 17:28:30 INFO MemoryStore: Block taskresult_1 stored as bytes in memory (estimated size 1891.8 KiB, free 362.5 MiB)
21/12/04 17:28:30 INFO BlockManagerInfo: Added taskresult_1 in memory on 10.0.2.15:40275 (size: 1891.8 KiB, free: 362.6 MiB)
21/12/04 17:28:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1937179 bytes result sent via BlockManager)
21/12/04 17:28:30 INFO TransportClientFactory: Successfully created connection to /10.0.2.15:40275 after 41 ms (0 ms spent in bootstraps)
21/12/04 17:28:30 INFO BlockManagerInfo: Removed taskresult_1 on 10.0.2.15:40275 in memory (size: 1891.8 KiB, free: 364.4 MiB)
21/12/04 17:28:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 456 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/12/04 17:28:30 INFO DAGScheduler: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.494 s
21/12/04 17:28:30 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/12/04 17:28:30 INFO DAGScheduler: Job 2 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.520056 s
21/12/04 17:28:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:30 INFO DAGScheduler: Got job 3 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:30 INFO DAGScheduler: Final stage: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:30 INFO DAGScheduler: Submitting ResultStage 2 (BlockRDD[2] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 1968.0 B, free 364.4 MiB)
21/12/04 17:28:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1210.0 B, free 364.3 MiB)
21/12/04 17:28:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 364.4 MiB)
21/12/04 17:28:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (BlockRDD[2] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
21/12/04 17:28:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/12/04 17:28:30 INFO BlockManager: Found block input-0-1638619106200 locally
21/12/04 17:28:30 INFO MemoryStore: Block taskresult_2 stored as bytes in memory (estimated size 1891.8 KiB, free 362.5 MiB)
21/12/04 17:28:30 INFO BlockManagerInfo: Added taskresult_2 in memory on 10.0.2.15:40275 (size: 1891.8 KiB, free: 362.6 MiB)
21/12/04 17:28:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1937179 bytes result sent via BlockManager)
21/12/04 17:28:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 80 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:30 INFO DAGScheduler: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.104 s
21/12/04 17:28:30 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/12/04 17:28:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/12/04 17:28:30 INFO DAGScheduler: Job 3 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.118171 s
21/12/04 17:28:30 INFO BlockManagerInfo: Removed taskresult_2 on 10.0.2.15:40275 in memory (size: 1891.8 KiB, free: 364.4 MiB)
21/12/04 17:28:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/pes1ug19cs458/Desktop/git_repo/src/spark-warehouse').
21/12/04 17:28:31 INFO SharedState: Warehouse path is 'file:/home/pes1ug19cs458/Desktop/git_repo/src/spark-warehouse'.
21/12/04 17:28:31 INFO MemoryStore: Block input-0-1638619111200 stored as values in memory (estimated size 1668.5 KiB, free 362.7 MiB)
21/12/04 17:28:31 INFO BlockManagerInfo: Added input-0-1638619111200 in memory on 10.0.2.15:40275 (size: 1668.5 KiB, free: 362.8 MiB)
21/12/04 17:28:31 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:28:31 WARN BlockManager: Block input-0-1638619111200 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:28:31 INFO BlockGenerator: Pushed block input-0-1638619111200
21/12/04 17:28:32 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:28:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:28:35 INFO JobScheduler: Added jobs for time 1638619115000 ms
21/12/04 17:28:35 INFO CodeGenerator: Code generated in 331.720976 ms
21/12/04 17:28:35 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:28:35 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:28:35 INFO DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:28:35 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:35 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:35 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[10] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.9 KiB, free 362.7 MiB)
21/12/04 17:28:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.7 MiB)
21/12/04 17:28:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.8 MiB)
21/12/04 17:28:35 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[10] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:35 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
21/12/04 17:28:35 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 568735 bytes) taskResourceAssignments Map()
21/12/04 17:28:35 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/12/04 17:28:36 INFO MemoryStore: Block input-0-1638619116200 stored as values in memory (estimated size 1735.4 KiB, free 361.0 MiB)
21/12/04 17:28:36 INFO BlockManagerInfo: Added input-0-1638619116200 in memory on 10.0.2.15:40275 (size: 1735.4 KiB, free: 361.1 MiB)
21/12/04 17:28:36 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:28:36 WARN BlockManager: Block input-0-1638619116200 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:28:36 INFO BlockGenerator: Pushed block input-0-1638619116200
21/12/04 17:28:36 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2197 bytes result sent to driver
21/12/04 17:28:36 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 754 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/12/04 17:28:36 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 39713
21/12/04 17:28:36 INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.825 s
21/12/04 17:28:36 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/12/04 17:28:36 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.846129 s
21/12/04 17:28:36 INFO CodeGenerator: Code generated in 21.007379 ms
21/12/04 17:28:36 INFO JobScheduler: Finished job streaming job 1638619110000 ms.0 from job set of time 1638619110000 ms
21/12/04 17:28:36 INFO JobScheduler: Total delay: 6.582 s for time 1638619110000 ms (execution: 6.574 s)
21/12/04 17:28:36 INFO JobScheduler: Starting job streaming job 1638619115000 ms.0 from job set of time 1638619115000 ms
21/12/04 17:28:36 INFO BlockRDD: Removing RDD 1 from persistence list
21/12/04 17:28:36 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[1] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619110000 ms
21/12/04 17:28:36 INFO ReceivedBlockTracker: Deleting batches: 
21/12/04 17:28:36 INFO InputInfoTracker: remove old batch metadata: 
21/12/04 17:28:36 INFO BlockManager: Removing RDD 1
21/12/04 17:28:36 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:36 INFO DAGScheduler: Got job 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:36 INFO DAGScheduler: Final stage: ResultStage 4 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:36 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:36 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:36 INFO DAGScheduler: Submitting ResultStage 4 (BlockRDD[8] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 1968.0 B, free 361.0 MiB)
21/12/04 17:28:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1210.0 B, free 361.0 MiB)
21/12/04 17:28:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 361.1 MiB)
21/12/04 17:28:36 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (BlockRDD[8] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:36 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
21/12/04 17:28:36 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:36 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/12/04 17:28:36 INFO BlockManager: Found block input-0-1638619111200 locally
21/12/04 17:28:36 INFO MemoryStore: Block taskresult_4 stored as bytes in memory (estimated size 1677.5 KiB, free 359.4 MiB)
21/12/04 17:28:36 INFO BlockManagerInfo: Added taskresult_4 in memory on 10.0.2.15:40275 (size: 1677.5 KiB, free: 359.5 MiB)
21/12/04 17:28:36 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1717810 bytes result sent via BlockManager)
21/12/04 17:28:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 74 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/12/04 17:28:36 INFO DAGScheduler: ResultStage 4 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.098 s
21/12/04 17:28:36 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
21/12/04 17:28:36 INFO DAGScheduler: Job 5 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.114397 s
21/12/04 17:28:36 INFO BlockManagerInfo: Removed taskresult_4 on 10.0.2.15:40275 in memory (size: 1677.5 KiB, free: 361.1 MiB)
21/12/04 17:28:36 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:36 INFO DAGScheduler: Got job 6 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:36 INFO DAGScheduler: Final stage: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:36 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:36 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:36 INFO DAGScheduler: Submitting ResultStage 5 (BlockRDD[8] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1968.0 B, free 361.0 MiB)
21/12/04 17:28:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1210.0 B, free 361.0 MiB)
21/12/04 17:28:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 361.1 MiB)
21/12/04 17:28:36 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (BlockRDD[8] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
21/12/04 17:28:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:36 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/12/04 17:28:36 INFO BlockManager: Found block input-0-1638619111200 locally
21/12/04 17:28:36 INFO MemoryStore: Block taskresult_5 stored as bytes in memory (estimated size 1677.5 KiB, free 359.4 MiB)
21/12/04 17:28:36 INFO BlockManagerInfo: Added taskresult_5 in memory on 10.0.2.15:40275 (size: 1677.5 KiB, free: 359.5 MiB)
21/12/04 17:28:36 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1717810 bytes result sent via BlockManager)
21/12/04 17:28:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 78 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/12/04 17:28:36 INFO BlockManagerInfo: Removed taskresult_5 on 10.0.2.15:40275 in memory (size: 1677.5 KiB, free: 361.1 MiB)
21/12/04 17:28:36 INFO DAGScheduler: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.096 s
21/12/04 17:28:36 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/12/04 17:28:36 INFO DAGScheduler: Job 6 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.107773 s
21/12/04 17:28:37 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:28:37 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:28:37 INFO DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:28:37 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:37 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:37 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.9 KiB, free 361.0 MiB)
21/12/04 17:28:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 361.0 MiB)
21/12/04 17:28:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 361.1 MiB)
21/12/04 17:28:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
21/12/04 17:28:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 420601 bytes) taskResourceAssignments Map()
21/12/04 17:28:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/12/04 17:28:37 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2198 bytes result sent to driver
21/12/04 17:28:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 36 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/12/04 17:28:37 INFO DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0) finished in 0.063 s
21/12/04 17:28:37 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/12/04 17:28:37 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0.077220 s
21/12/04 17:28:37 INFO JobScheduler: Finished job streaming job 1638619115000 ms.0 from job set of time 1638619115000 ms
21/12/04 17:28:37 INFO JobScheduler: Total delay: 2.190 s for time 1638619115000 ms (execution: 0.607 s)
21/12/04 17:28:37 INFO BlockRDD: Removing RDD 2 from persistence list
21/12/04 17:28:37 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[2] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619115000 ms
21/12/04 17:28:37 INFO BlockManager: Removing RDD 2
21/12/04 17:28:37 INFO ReceivedBlockTracker: Deleting batches: 1638619105000 ms
21/12/04 17:28:37 INFO InputInfoTracker: remove old batch metadata: 1638619105000 ms
21/12/04 17:28:37 INFO BlockManagerInfo: Removed input-0-1638619106200 on 10.0.2.15:40275 in memory (size: 1881.7 KiB, free: 362.9 MiB)
21/12/04 17:28:40 INFO JobScheduler: Added jobs for time 1638619120000 ms
21/12/04 17:28:40 INFO JobScheduler: Starting job streaming job 1638619120000 ms.0 from job set of time 1638619120000 ms
21/12/04 17:28:40 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:40 INFO DAGScheduler: Got job 8 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:40 INFO DAGScheduler: Final stage: ResultStage 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:40 INFO DAGScheduler: Submitting ResultStage 7 (BlockRDD[18] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:28:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (BlockRDD[18] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:40 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
21/12/04 17:28:40 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:40 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/12/04 17:28:40 INFO BlockManager: Found block input-0-1638619116200 locally
21/12/04 17:28:40 INFO MemoryStore: Block taskresult_7 stored as bytes in memory (estimated size 1744.7 KiB, free 361.1 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Added taskresult_7 in memory on 10.0.2.15:40275 (size: 1744.7 KiB, free: 361.2 MiB)
21/12/04 17:28:40 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1786572 bytes result sent via BlockManager)
21/12/04 17:28:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 52 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:40 INFO DAGScheduler: ResultStage 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.067 s
21/12/04 17:28:40 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:40 INFO BlockManagerInfo: Removed taskresult_7 on 10.0.2.15:40275 in memory (size: 1744.7 KiB, free: 362.9 MiB)
21/12/04 17:28:40 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/12/04 17:28:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/12/04 17:28:40 INFO DAGScheduler: Job 8 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.096861 s
21/12/04 17:28:40 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:40 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:40 INFO DAGScheduler: Got job 9 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:40 INFO DAGScheduler: Final stage: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:40 INFO DAGScheduler: Submitting ResultStage 8 (BlockRDD[18] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:28:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:40 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (BlockRDD[18] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:40 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
21/12/04 17:28:40 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:40 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/12/04 17:28:40 INFO BlockManager: Found block input-0-1638619116200 locally
21/12/04 17:28:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:40 INFO MemoryStore: Block taskresult_8 stored as bytes in memory (estimated size 1744.7 KiB, free 361.2 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Added taskresult_8 in memory on 10.0.2.15:40275 (size: 1744.7 KiB, free: 361.2 MiB)
21/12/04 17:28:40 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1786572 bytes result sent via BlockManager)
21/12/04 17:28:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 94 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:40 INFO BlockManagerInfo: Removed taskresult_8 on 10.0.2.15:40275 in memory (size: 1744.7 KiB, free: 362.9 MiB)
21/12/04 17:28:40 INFO DAGScheduler: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.120 s
21/12/04 17:28:40 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/12/04 17:28:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/12/04 17:28:40 INFO DAGScheduler: Job 9 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.126505 s
21/12/04 17:28:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:28:40 INFO DAGScheduler: Got job 10 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:28:40 INFO DAGScheduler: Final stage: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:28:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:40 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[25] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:28:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.8 MiB)
21/12/04 17:28:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:28:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[25] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
21/12/04 17:28:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 505801 bytes) taskResourceAssignments Map()
21/12/04 17:28:40 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/12/04 17:28:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2413 bytes result sent to driver
21/12/04 17:28:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 45 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/12/04 17:28:40 INFO DAGScheduler: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0.062 s
21/12/04 17:28:40 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/12/04 17:28:40 INFO DAGScheduler: Job 10 finished: showString at NativeMethodAccessorImpl.java:0, took 0.071193 s
21/12/04 17:28:40 INFO JobScheduler: Finished job streaming job 1638619120000 ms.0 from job set of time 1638619120000 ms
21/12/04 17:28:40 INFO JobScheduler: Total delay: 0.550 s for time 1638619120000 ms (execution: 0.540 s)
21/12/04 17:28:40 INFO BlockRDD: Removing RDD 8 from persistence list
21/12/04 17:28:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[8] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619120000 ms
21/12/04 17:28:40 INFO ReceivedBlockTracker: Deleting batches: 1638619110000 ms
21/12/04 17:28:40 INFO BlockManager: Removing RDD 8
21/12/04 17:28:40 INFO InputInfoTracker: remove old batch metadata: 1638619110000 ms
21/12/04 17:28:40 INFO BlockManagerInfo: Removed input-0-1638619111200 on 10.0.2.15:40275 in memory (size: 1668.5 KiB, free: 364.6 MiB)
21/12/04 17:28:41 INFO MemoryStore: Block input-0-1638619121200 stored as values in memory (estimated size 1735.8 KiB, free 362.8 MiB)
21/12/04 17:28:41 INFO BlockManagerInfo: Added input-0-1638619121200 in memory on 10.0.2.15:40275 (size: 1735.8 KiB, free: 362.9 MiB)
21/12/04 17:28:41 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:28:41 WARN BlockManager: Block input-0-1638619121200 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:28:41 INFO BlockGenerator: Pushed block input-0-1638619121200
21/12/04 17:28:45 INFO JobScheduler: Added jobs for time 1638619125000 ms
21/12/04 17:28:45 INFO JobScheduler: Starting job streaming job 1638619125000 ms.0 from job set of time 1638619125000 ms
21/12/04 17:28:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:45 INFO DAGScheduler: Got job 11 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:45 INFO DAGScheduler: Final stage: ResultStage 10 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:45 INFO DAGScheduler: Submitting ResultStage 10 (BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:45 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:28:45 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:28:45 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:45 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:45 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
21/12/04 17:28:45 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:45 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/12/04 17:28:45 INFO BlockManager: Found block input-0-1638619121200 locally
21/12/04 17:28:45 INFO MemoryStore: Block taskresult_10 stored as bytes in memory (estimated size 1745.2 KiB, free 361.1 MiB)
21/12/04 17:28:45 INFO BlockManagerInfo: Added taskresult_10 in memory on 10.0.2.15:40275 (size: 1745.2 KiB, free: 361.2 MiB)
21/12/04 17:28:45 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1787036 bytes result sent via BlockManager)
21/12/04 17:28:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 60 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:45 INFO DAGScheduler: ResultStage 10 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.076 s
21/12/04 17:28:45 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:45 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/12/04 17:28:45 INFO BlockManagerInfo: Removed taskresult_10 on 10.0.2.15:40275 in memory (size: 1745.2 KiB, free: 362.9 MiB)
21/12/04 17:28:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/12/04 17:28:45 INFO DAGScheduler: Job 11 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.095237 s
21/12/04 17:28:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:45 INFO DAGScheduler: Got job 12 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:45 INFO DAGScheduler: Final stage: ResultStage 11 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:45 INFO DAGScheduler: Submitting ResultStage 11 (BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:45 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:28:45 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:28:45 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:45 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:45 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
21/12/04 17:28:45 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:45 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/12/04 17:28:45 INFO BlockManager: Found block input-0-1638619121200 locally
21/12/04 17:28:45 INFO MemoryStore: Block taskresult_11 stored as bytes in memory (estimated size 1745.2 KiB, free 361.1 MiB)
21/12/04 17:28:45 INFO BlockManagerInfo: Added taskresult_11 in memory on 10.0.2.15:40275 (size: 1745.2 KiB, free: 361.2 MiB)
21/12/04 17:28:45 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1787036 bytes result sent via BlockManager)
21/12/04 17:28:45 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 74 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:45 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/12/04 17:28:45 INFO DAGScheduler: ResultStage 11 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.094 s
21/12/04 17:28:45 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/12/04 17:28:45 INFO DAGScheduler: Job 12 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.099074 s
21/12/04 17:28:45 INFO BlockManagerInfo: Removed taskresult_11 on 10.0.2.15:40275 in memory (size: 1745.2 KiB, free: 362.9 MiB)
21/12/04 17:28:45 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:28:45 INFO DAGScheduler: Got job 13 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:28:45 INFO DAGScheduler: Final stage: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:28:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:45 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[33] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:45 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 10.9 KiB, free 362.8 MiB)
21/12/04 17:28:45 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.8 MiB)
21/12/04 17:28:45 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:28:45 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[33] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:45 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
21/12/04 17:28:45 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 598056 bytes) taskResourceAssignments Map()
21/12/04 17:28:45 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/12/04 17:28:45 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2187 bytes result sent to driver
21/12/04 17:28:45 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 33 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:45 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/12/04 17:28:45 INFO DAGScheduler: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0) finished in 0.075 s
21/12/04 17:28:45 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
21/12/04 17:28:45 INFO DAGScheduler: Job 13 finished: showString at NativeMethodAccessorImpl.java:0, took 0.092854 s
21/12/04 17:28:45 INFO JobScheduler: Finished job streaming job 1638619125000 ms.0 from job set of time 1638619125000 ms
21/12/04 17:28:45 INFO JobScheduler: Total delay: 0.512 s for time 1638619125000 ms (execution: 0.506 s)
21/12/04 17:28:45 INFO BlockRDD: Removing RDD 18 from persistence list
21/12/04 17:28:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[18] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619125000 ms
21/12/04 17:28:45 INFO ReceivedBlockTracker: Deleting batches: 1638619115000 ms
21/12/04 17:28:45 INFO InputInfoTracker: remove old batch metadata: 1638619115000 ms
21/12/04 17:28:45 INFO BlockManager: Removing RDD 18
21/12/04 17:28:45 INFO BlockManagerInfo: Removed input-0-1638619116200 on 10.0.2.15:40275 in memory (size: 1735.4 KiB, free: 364.6 MiB)
21/12/04 17:28:46 INFO MemoryStore: Block input-0-1638619126200 stored as values in memory (estimated size 1722.1 KiB, free 362.8 MiB)
21/12/04 17:28:46 INFO BlockManagerInfo: Added input-0-1638619126200 in memory on 10.0.2.15:40275 (size: 1722.1 KiB, free: 362.9 MiB)
21/12/04 17:28:46 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:28:46 WARN BlockManager: Block input-0-1638619126200 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:28:46 INFO BlockGenerator: Pushed block input-0-1638619126200
21/12/04 17:28:50 INFO JobScheduler: Added jobs for time 1638619130000 ms
21/12/04 17:28:50 INFO JobScheduler: Starting job streaming job 1638619130000 ms.0 from job set of time 1638619130000 ms
21/12/04 17:28:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:50 INFO DAGScheduler: Got job 14 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:50 INFO DAGScheduler: Final stage: ResultStage 13 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:50 INFO DAGScheduler: Submitting ResultStage 13 (BlockRDD[34] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:50 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:28:50 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:50 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (BlockRDD[34] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:50 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
21/12/04 17:28:50 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:50 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/12/04 17:28:50 INFO BlockManager: Found block input-0-1638619126200 locally
21/12/04 17:28:50 INFO MemoryStore: Block taskresult_13 stored as bytes in memory (estimated size 1731.3 KiB, free 361.1 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Added taskresult_13 in memory on 10.0.2.15:40275 (size: 1731.3 KiB, free: 361.2 MiB)
21/12/04 17:28:50 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1772870 bytes result sent via BlockManager)
21/12/04 17:28:50 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 167 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:50 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/12/04 17:28:50 INFO DAGScheduler: ResultStage 13 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.202 s
21/12/04 17:28:50 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/12/04 17:28:50 INFO DAGScheduler: Job 14 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.212421 s
21/12/04 17:28:50 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.2 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Removed taskresult_13 on 10.0.2.15:40275 in memory (size: 1731.3 KiB, free: 362.9 MiB)
21/12/04 17:28:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:50 INFO DAGScheduler: Got job 15 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:50 INFO DAGScheduler: Final stage: ResultStage 14 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:50 INFO DAGScheduler: Submitting ResultStage 14 (BlockRDD[34] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:50 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:28:50 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:28:50 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (BlockRDD[34] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:50 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
21/12/04 17:28:50 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:50 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/12/04 17:28:50 INFO BlockManager: Found block input-0-1638619126200 locally
21/12/04 17:28:50 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:28:50 INFO MemoryStore: Block taskresult_14 stored as bytes in memory (estimated size 1731.3 KiB, free 361.1 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Added taskresult_14 in memory on 10.0.2.15:40275 (size: 1731.3 KiB, free: 361.2 MiB)
21/12/04 17:28:50 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1772870 bytes result sent via BlockManager)
21/12/04 17:28:50 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.2 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 361.2 MiB)
21/12/04 17:28:50 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 124 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:50 INFO DAGScheduler: ResultStage 14 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.154 s
21/12/04 17:28:50 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/12/04 17:28:50 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/12/04 17:28:50 INFO DAGScheduler: Job 15 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.163443 s
21/12/04 17:28:50 INFO BlockManagerInfo: Removed taskresult_14 on 10.0.2.15:40275 in memory (size: 1731.3 KiB, free: 362.9 MiB)
21/12/04 17:28:50 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:28:50 INFO DAGScheduler: Got job 16 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:28:50 INFO DAGScheduler: Final stage: ResultStage 15 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:28:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:50 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[41] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:50 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 10.9 KiB, free 362.8 MiB)
21/12/04 17:28:50 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.8 MiB)
21/12/04 17:28:50 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:28:50 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[41] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:50 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
21/12/04 17:28:50 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 470765 bytes) taskResourceAssignments Map()
21/12/04 17:28:50 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/12/04 17:28:50 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2435 bytes result sent to driver
21/12/04 17:28:50 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 31 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:50 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/12/04 17:28:50 INFO DAGScheduler: ResultStage 15 (showString at NativeMethodAccessorImpl.java:0) finished in 0.050 s
21/12/04 17:28:50 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/12/04 17:28:50 INFO DAGScheduler: Job 16 finished: showString at NativeMethodAccessorImpl.java:0, took 0.063801 s
21/12/04 17:28:50 INFO JobScheduler: Finished job streaming job 1638619130000 ms.0 from job set of time 1638619130000 ms
21/12/04 17:28:50 INFO JobScheduler: Total delay: 0.730 s for time 1638619130000 ms (execution: 0.720 s)
21/12/04 17:28:50 INFO BlockRDD: Removing RDD 26 from persistence list
21/12/04 17:28:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619130000 ms
21/12/04 17:28:50 INFO ReceivedBlockTracker: Deleting batches: 1638619120000 ms
21/12/04 17:28:50 INFO InputInfoTracker: remove old batch metadata: 1638619120000 ms
21/12/04 17:28:50 INFO BlockManager: Removing RDD 26
21/12/04 17:28:50 INFO BlockManagerInfo: Removed input-0-1638619121200 on 10.0.2.15:40275 in memory (size: 1735.8 KiB, free: 364.6 MiB)
21/12/04 17:28:51 INFO MemoryStore: Block input-0-1638619131200 stored as values in memory (estimated size 1869.4 KiB, free 362.7 MiB)
21/12/04 17:28:51 INFO BlockManagerInfo: Added input-0-1638619131200 in memory on 10.0.2.15:40275 (size: 1869.4 KiB, free: 362.8 MiB)
21/12/04 17:28:51 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:28:51 WARN BlockManager: Block input-0-1638619131200 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:28:51 INFO BlockGenerator: Pushed block input-0-1638619131200
21/12/04 17:28:55 INFO JobScheduler: Added jobs for time 1638619135000 ms
21/12/04 17:28:55 INFO JobScheduler: Starting job streaming job 1638619135000 ms.0 from job set of time 1638619135000 ms
21/12/04 17:28:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:55 INFO DAGScheduler: Got job 17 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:55 INFO DAGScheduler: Final stage: ResultStage 16 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:55 INFO DAGScheduler: Submitting ResultStage 16 (BlockRDD[42] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:55 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 1968.0 B, free 362.7 MiB)
21/12/04 17:28:55 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.7 MiB)
21/12/04 17:28:55 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:28:55 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (BlockRDD[42] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:55 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
21/12/04 17:28:55 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:55 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/12/04 17:28:55 INFO BlockManager: Found block input-0-1638619131200 locally
21/12/04 17:28:55 INFO MemoryStore: Block taskresult_16 stored as bytes in memory (estimated size 1879.4 KiB, free 360.8 MiB)
21/12/04 17:28:55 INFO BlockManagerInfo: Added taskresult_16 in memory on 10.0.2.15:40275 (size: 1879.4 KiB, free: 360.9 MiB)
21/12/04 17:28:55 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1924486 bytes result sent via BlockManager)
21/12/04 17:28:55 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 118 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:55 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/12/04 17:28:55 INFO DAGScheduler: ResultStage 16 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.131 s
21/12/04 17:28:55 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
21/12/04 17:28:55 INFO DAGScheduler: Job 17 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.135832 s
21/12/04 17:28:55 INFO BlockManagerInfo: Removed taskresult_16 on 10.0.2.15:40275 in memory (size: 1879.4 KiB, free: 362.8 MiB)
21/12/04 17:28:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:28:55 INFO DAGScheduler: Got job 18 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:28:55 INFO DAGScheduler: Final stage: ResultStage 17 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:28:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:55 INFO DAGScheduler: Submitting ResultStage 17 (BlockRDD[42] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:55 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 1968.0 B, free 362.7 MiB)
21/12/04 17:28:55 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.7 MiB)
21/12/04 17:28:55 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:28:55 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (BlockRDD[42] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:55 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
21/12/04 17:28:55 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:28:55 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/12/04 17:28:55 INFO BlockManager: Found block input-0-1638619131200 locally
21/12/04 17:28:55 INFO MemoryStore: Block taskresult_17 stored as bytes in memory (estimated size 1879.4 KiB, free 360.8 MiB)
21/12/04 17:28:55 INFO BlockManagerInfo: Added taskresult_17 in memory on 10.0.2.15:40275 (size: 1879.4 KiB, free: 360.9 MiB)
21/12/04 17:28:55 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1924486 bytes result sent via BlockManager)
21/12/04 17:28:55 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 107 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:55 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/12/04 17:28:55 INFO DAGScheduler: ResultStage 17 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.121 s
21/12/04 17:28:55 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/12/04 17:28:55 INFO BlockManagerInfo: Removed taskresult_17 on 10.0.2.15:40275 in memory (size: 1879.4 KiB, free: 362.8 MiB)
21/12/04 17:28:55 INFO DAGScheduler: Job 18 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.133865 s
21/12/04 17:28:55 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:28:55 INFO DAGScheduler: Got job 19 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:28:55 INFO DAGScheduler: Final stage: ResultStage 18 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:28:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:28:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:28:55 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[49] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:28:55 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.9 KiB, free 362.6 MiB)
21/12/04 17:28:55 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.6 MiB)
21/12/04 17:28:55 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:28:55 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1388
21/12/04 17:28:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[49] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:28:55 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
21/12/04 17:28:55 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 423919 bytes) taskResourceAssignments Map()
21/12/04 17:28:55 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/12/04 17:28:55 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2506 bytes result sent to driver
21/12/04 17:28:55 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 26 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:28:55 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/12/04 17:28:55 INFO DAGScheduler: ResultStage 18 (showString at NativeMethodAccessorImpl.java:0) finished in 0.053 s
21/12/04 17:28:55 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:28:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/12/04 17:28:55 INFO DAGScheduler: Job 19 finished: showString at NativeMethodAccessorImpl.java:0, took 0.062465 s
21/12/04 17:28:55 INFO JobScheduler: Finished job streaming job 1638619135000 ms.0 from job set of time 1638619135000 ms
21/12/04 17:28:55 INFO JobScheduler: Total delay: 0.615 s for time 1638619135000 ms (execution: 0.610 s)
21/12/04 17:28:55 INFO BlockRDD: Removing RDD 34 from persistence list
21/12/04 17:28:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[34] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619135000 ms
21/12/04 17:28:55 INFO ReceivedBlockTracker: Deleting batches: 1638619125000 ms
21/12/04 17:28:55 INFO BlockManager: Removing RDD 34
21/12/04 17:28:55 INFO InputInfoTracker: remove old batch metadata: 1638619125000 ms
21/12/04 17:28:55 INFO BlockManagerInfo: Removed input-0-1638619126200 on 10.0.2.15:40275 in memory (size: 1722.1 KiB, free: 364.4 MiB)
21/12/04 17:28:56 INFO MemoryStore: Block input-0-1638619136400 stored as values in memory (estimated size 1746.7 KiB, free 362.6 MiB)
21/12/04 17:28:56 INFO BlockManagerInfo: Added input-0-1638619136400 in memory on 10.0.2.15:40275 (size: 1746.7 KiB, free: 362.7 MiB)
21/12/04 17:28:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:28:56 WARN BlockManager: Block input-0-1638619136400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:28:56 INFO BlockGenerator: Pushed block input-0-1638619136400
21/12/04 17:29:00 INFO JobScheduler: Added jobs for time 1638619140000 ms
21/12/04 17:29:00 INFO JobScheduler: Starting job streaming job 1638619140000 ms.0 from job set of time 1638619140000 ms
21/12/04 17:29:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:00 INFO DAGScheduler: Got job 20 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:00 INFO DAGScheduler: Final stage: ResultStage 19 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:00 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:00 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:00 INFO DAGScheduler: Submitting ResultStage 19 (BlockRDD[50] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:00 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 1968.0 B, free 362.6 MiB)
21/12/04 17:29:00 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.6 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:00 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (BlockRDD[50] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:00 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
21/12/04 17:29:00 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:00 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/12/04 17:29:00 INFO BlockManager: Found block input-0-1638619136400 locally
21/12/04 17:29:00 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:00 INFO MemoryStore: Block taskresult_19 stored as bytes in memory (estimated size 1756.2 KiB, free 360.9 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Added taskresult_19 in memory on 10.0.2.15:40275 (size: 1756.2 KiB, free: 361.0 MiB)
21/12/04 17:29:00 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1798304 bytes result sent via BlockManager)
21/12/04 17:29:00 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 361.0 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.0 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 361.0 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.0 MiB)
21/12/04 17:29:00 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 115 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:00 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/12/04 17:29:00 INFO BlockManagerInfo: Removed taskresult_19 on 10.0.2.15:40275 in memory (size: 1756.2 KiB, free: 362.7 MiB)
21/12/04 17:29:00 INFO DAGScheduler: ResultStage 19 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.145 s
21/12/04 17:29:00 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/12/04 17:29:00 INFO DAGScheduler: Job 20 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.151791 s
21/12/04 17:29:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:00 INFO DAGScheduler: Got job 21 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:00 INFO DAGScheduler: Final stage: ResultStage 20 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:00 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:00 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:00 INFO DAGScheduler: Submitting ResultStage 20 (BlockRDD[50] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:00 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 1968.0 B, free 362.7 MiB)
21/12/04 17:29:00 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.7 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:00 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (BlockRDD[50] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:00 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
21/12/04 17:29:00 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:00 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/12/04 17:29:00 INFO BlockManager: Found block input-0-1638619136400 locally
21/12/04 17:29:00 INFO MemoryStore: Block taskresult_20 stored as bytes in memory (estimated size 1756.1 KiB, free 360.9 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Added taskresult_20 in memory on 10.0.2.15:40275 (size: 1756.1 KiB, free: 361.0 MiB)
21/12/04 17:29:00 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1798218 bytes result sent via BlockManager)
21/12/04 17:29:00 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 59 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:00 INFO DAGScheduler: ResultStage 20 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.079 s
21/12/04 17:29:00 INFO BlockManagerInfo: Removed taskresult_20 on 10.0.2.15:40275 in memory (size: 1756.1 KiB, free: 362.7 MiB)
21/12/04 17:29:00 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:00 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/12/04 17:29:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/12/04 17:29:00 INFO DAGScheduler: Job 21 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.086954 s
21/12/04 17:29:00 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:00 INFO DAGScheduler: Got job 22 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:00 INFO DAGScheduler: Final stage: ResultStage 21 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:00 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:00 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:00 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[57] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:00 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 10.9 KiB, free 362.6 MiB)
21/12/04 17:29:00 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.6 MiB)
21/12/04 17:29:00 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:29:00 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[57] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:00 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
21/12/04 17:29:00 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 490717 bytes) taskResourceAssignments Map()
21/12/04 17:29:00 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/12/04 17:29:00 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 2242 bytes result sent to driver
21/12/04 17:29:00 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 28 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:00 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/12/04 17:29:00 INFO DAGScheduler: ResultStage 21 (showString at NativeMethodAccessorImpl.java:0) finished in 0.041 s
21/12/04 17:29:00 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
21/12/04 17:29:00 INFO DAGScheduler: Job 22 finished: showString at NativeMethodAccessorImpl.java:0, took 0.058647 s
21/12/04 17:29:00 INFO JobScheduler: Finished job streaming job 1638619140000 ms.0 from job set of time 1638619140000 ms
21/12/04 17:29:00 INFO JobScheduler: Total delay: 0.538 s for time 1638619140000 ms (execution: 0.523 s)
21/12/04 17:29:00 INFO BlockRDD: Removing RDD 42 from persistence list
21/12/04 17:29:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[42] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619140000 ms
21/12/04 17:29:00 INFO BlockManager: Removing RDD 42
21/12/04 17:29:00 INFO ReceivedBlockTracker: Deleting batches: 1638619130000 ms
21/12/04 17:29:00 INFO InputInfoTracker: remove old batch metadata: 1638619130000 ms
21/12/04 17:29:00 INFO BlockManagerInfo: Removed input-0-1638619131200 on 10.0.2.15:40275 in memory (size: 1869.4 KiB, free: 364.6 MiB)
21/12/04 17:29:01 INFO MemoryStore: Block input-0-1638619141400 stored as values in memory (estimated size 1653.4 KiB, free 362.9 MiB)
21/12/04 17:29:01 INFO BlockManagerInfo: Added input-0-1638619141400 in memory on 10.0.2.15:40275 (size: 1653.4 KiB, free: 362.9 MiB)
21/12/04 17:29:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:01 WARN BlockManager: Block input-0-1638619141400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:01 INFO BlockGenerator: Pushed block input-0-1638619141400
21/12/04 17:29:05 INFO JobScheduler: Added jobs for time 1638619145000 ms
21/12/04 17:29:05 INFO JobScheduler: Starting job streaming job 1638619145000 ms.0 from job set of time 1638619145000 ms
21/12/04 17:29:05 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:05 INFO DAGScheduler: Got job 23 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:05 INFO DAGScheduler: Final stage: ResultStage 22 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:05 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:05 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:05 INFO DAGScheduler: Submitting ResultStage 22 (BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:05 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:29:05 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:29:05 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:05 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:05 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
21/12/04 17:29:05 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:05 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/12/04 17:29:05 INFO BlockManager: Found block input-0-1638619141400 locally
21/12/04 17:29:05 INFO MemoryStore: Block taskresult_22 stored as bytes in memory (estimated size 1662.3 KiB, free 361.2 MiB)
21/12/04 17:29:05 INFO BlockManagerInfo: Added taskresult_22 in memory on 10.0.2.15:40275 (size: 1662.3 KiB, free: 361.3 MiB)
21/12/04 17:29:05 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1702183 bytes result sent via BlockManager)
21/12/04 17:29:05 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 47 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:05 INFO BlockManagerInfo: Removed taskresult_22 on 10.0.2.15:40275 in memory (size: 1662.3 KiB, free: 362.9 MiB)
21/12/04 17:29:05 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/12/04 17:29:05 INFO DAGScheduler: ResultStage 22 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.059 s
21/12/04 17:29:05 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/12/04 17:29:05 INFO DAGScheduler: Job 23 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.063265 s
21/12/04 17:29:05 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:05 INFO DAGScheduler: Got job 24 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:05 INFO DAGScheduler: Final stage: ResultStage 23 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:05 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:05 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:05 INFO DAGScheduler: Submitting ResultStage 23 (BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:05 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:29:05 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:29:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:05 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:05 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
21/12/04 17:29:05 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:05 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/12/04 17:29:05 INFO BlockManager: Found block input-0-1638619141400 locally
21/12/04 17:29:05 INFO MemoryStore: Block taskresult_23 stored as bytes in memory (estimated size 1662.3 KiB, free 361.2 MiB)
21/12/04 17:29:05 INFO BlockManagerInfo: Added taskresult_23 in memory on 10.0.2.15:40275 (size: 1662.3 KiB, free: 361.3 MiB)
21/12/04 17:29:05 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1702183 bytes result sent via BlockManager)
21/12/04 17:29:05 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 69 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:05 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/12/04 17:29:05 INFO DAGScheduler: ResultStage 23 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.080 s
21/12/04 17:29:05 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/12/04 17:29:05 INFO DAGScheduler: Job 24 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.089378 s
21/12/04 17:29:05 INFO BlockManagerInfo: Removed taskresult_23 on 10.0.2.15:40275 in memory (size: 1662.3 KiB, free: 362.9 MiB)
21/12/04 17:29:05 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:05 INFO DAGScheduler: Got job 25 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:05 INFO DAGScheduler: Final stage: ResultStage 24 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:05 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:05 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:05 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[65] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:05 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 10.9 KiB, free 362.8 MiB)
21/12/04 17:29:05 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.8 MiB)
21/12/04 17:29:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:29:05 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[65] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:05 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
21/12/04 17:29:05 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 356897 bytes) taskResourceAssignments Map()
21/12/04 17:29:05 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/12/04 17:29:05 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2247 bytes result sent to driver
21/12/04 17:29:05 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 268 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:05 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/12/04 17:29:05 INFO DAGScheduler: ResultStage 24 (showString at NativeMethodAccessorImpl.java:0) finished in 0.287 s
21/12/04 17:29:05 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
21/12/04 17:29:05 INFO DAGScheduler: Job 25 finished: showString at NativeMethodAccessorImpl.java:0, took 0.294344 s
21/12/04 17:29:05 INFO JobScheduler: Finished job streaming job 1638619145000 ms.0 from job set of time 1638619145000 ms
21/12/04 17:29:05 INFO JobScheduler: Total delay: 0.666 s for time 1638619145000 ms (execution: 0.660 s)
21/12/04 17:29:05 INFO BlockRDD: Removing RDD 50 from persistence list
21/12/04 17:29:05 INFO BlockManager: Removing RDD 50
21/12/04 17:29:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[50] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619145000 ms
21/12/04 17:29:05 INFO ReceivedBlockTracker: Deleting batches: 1638619135000 ms
21/12/04 17:29:05 INFO BlockManagerInfo: Removed input-0-1638619136400 on 10.0.2.15:40275 in memory (size: 1746.7 KiB, free: 364.6 MiB)
21/12/04 17:29:05 INFO InputInfoTracker: remove old batch metadata: 1638619135000 ms
21/12/04 17:29:06 INFO MemoryStore: Block input-0-1638619146400 stored as values in memory (estimated size 1597.7 KiB, free 363.0 MiB)
21/12/04 17:29:06 INFO BlockManagerInfo: Added input-0-1638619146400 in memory on 10.0.2.15:40275 (size: 1597.7 KiB, free: 363.1 MiB)
21/12/04 17:29:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:06 WARN BlockManager: Block input-0-1638619146400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:06 INFO BlockGenerator: Pushed block input-0-1638619146400
21/12/04 17:29:10 INFO JobScheduler: Added jobs for time 1638619150000 ms
21/12/04 17:29:10 INFO JobScheduler: Starting job streaming job 1638619150000 ms.0 from job set of time 1638619150000 ms
21/12/04 17:29:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:10 INFO DAGScheduler: Got job 26 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:10 INFO DAGScheduler: Final stage: ResultStage 25 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:10 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:10 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:10 INFO DAGScheduler: Submitting ResultStage 25 (BlockRDD[66] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:10 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 1968.0 B, free 363.0 MiB)
21/12/04 17:29:10 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.0 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:10 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (BlockRDD[66] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
21/12/04 17:29:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:10 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/12/04 17:29:10 INFO BlockManager: Found block input-0-1638619146400 locally
21/12/04 17:29:10 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.1 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:10 INFO MemoryStore: Block taskresult_25 stored as bytes in memory (estimated size 1606.4 KiB, free 361.4 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Added taskresult_25 in memory on 10.0.2.15:40275 (size: 1606.4 KiB, free: 361.5 MiB)
21/12/04 17:29:10 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1644951 bytes result sent via BlockManager)
21/12/04 17:29:10 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 361.5 MiB)
21/12/04 17:29:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 82 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:10 INFO BlockManagerInfo: Removed taskresult_25 on 10.0.2.15:40275 in memory (size: 1606.4 KiB, free: 363.1 MiB)
21/12/04 17:29:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/12/04 17:29:10 INFO DAGScheduler: ResultStage 25 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.126 s
21/12/04 17:29:10 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/12/04 17:29:10 INFO DAGScheduler: Job 26 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.130310 s
21/12/04 17:29:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:10 INFO DAGScheduler: Got job 27 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:10 INFO DAGScheduler: Final stage: ResultStage 26 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:10 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:10 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:10 INFO DAGScheduler: Submitting ResultStage 26 (BlockRDD[66] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:10 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 1968.0 B, free 363.0 MiB)
21/12/04 17:29:10 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.0 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:10 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (BlockRDD[66] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:10 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
21/12/04 17:29:10 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:10 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/12/04 17:29:10 INFO BlockManager: Found block input-0-1638619146400 locally
21/12/04 17:29:10 INFO MemoryStore: Block taskresult_26 stored as bytes in memory (estimated size 1606.4 KiB, free 361.4 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Added taskresult_26 in memory on 10.0.2.15:40275 (size: 1606.4 KiB, free: 361.5 MiB)
21/12/04 17:29:10 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1644951 bytes result sent via BlockManager)
21/12/04 17:29:10 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 54 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:10 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/12/04 17:29:10 INFO BlockManagerInfo: Removed taskresult_26 on 10.0.2.15:40275 in memory (size: 1606.4 KiB, free: 363.1 MiB)
21/12/04 17:29:10 INFO DAGScheduler: ResultStage 26 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.066 s
21/12/04 17:29:10 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/12/04 17:29:10 INFO DAGScheduler: Job 27 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.071068 s
21/12/04 17:29:10 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:10 INFO DAGScheduler: Got job 28 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:10 INFO DAGScheduler: Final stage: ResultStage 27 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:10 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:10 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:10 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[73] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:10 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 10.9 KiB, free 363.0 MiB)
21/12/04 17:29:10 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 363.0 MiB)
21/12/04 17:29:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.1 MiB)
21/12/04 17:29:10 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[73] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:10 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
21/12/04 17:29:10 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 380152 bytes) taskResourceAssignments Map()
21/12/04 17:29:10 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/12/04 17:29:10 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 2183 bytes result sent to driver
21/12/04 17:29:10 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 35 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:10 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/12/04 17:29:10 INFO DAGScheduler: ResultStage 27 (showString at NativeMethodAccessorImpl.java:0) finished in 0.052 s
21/12/04 17:29:10 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/12/04 17:29:10 INFO DAGScheduler: Job 28 finished: showString at NativeMethodAccessorImpl.java:0, took 0.066050 s
21/12/04 17:29:10 INFO JobScheduler: Finished job streaming job 1638619150000 ms.0 from job set of time 1638619150000 ms
21/12/04 17:29:10 INFO JobScheduler: Total delay: 0.494 s for time 1638619150000 ms (execution: 0.481 s)
21/12/04 17:29:10 INFO BlockRDD: Removing RDD 58 from persistence list
21/12/04 17:29:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619150000 ms
21/12/04 17:29:10 INFO BlockManager: Removing RDD 58
21/12/04 17:29:10 INFO ReceivedBlockTracker: Deleting batches: 1638619140000 ms
21/12/04 17:29:10 INFO InputInfoTracker: remove old batch metadata: 1638619140000 ms
21/12/04 17:29:10 INFO BlockManagerInfo: Removed input-0-1638619141400 on 10.0.2.15:40275 in memory (size: 1653.4 KiB, free: 364.7 MiB)
21/12/04 17:29:11 INFO MemoryStore: Block input-0-1638619151400 stored as values in memory (estimated size 1824.6 KiB, free 362.8 MiB)
21/12/04 17:29:11 INFO BlockManagerInfo: Added input-0-1638619151400 in memory on 10.0.2.15:40275 (size: 1824.6 KiB, free: 362.9 MiB)
21/12/04 17:29:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:11 WARN BlockManager: Block input-0-1638619151400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:11 INFO BlockGenerator: Pushed block input-0-1638619151400
21/12/04 17:29:15 INFO JobScheduler: Added jobs for time 1638619155000 ms
21/12/04 17:29:15 INFO JobScheduler: Starting job streaming job 1638619155000 ms.0 from job set of time 1638619155000 ms
21/12/04 17:29:15 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:15 INFO DAGScheduler: Got job 29 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:15 INFO DAGScheduler: Final stage: ResultStage 28 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:15 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:15 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:15 INFO DAGScheduler: Submitting ResultStage 28 (BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:15 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:29:15 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:29:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:15 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:15 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
21/12/04 17:29:15 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:15 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
21/12/04 17:29:15 INFO BlockManager: Found block input-0-1638619151400 locally
21/12/04 17:29:15 INFO MemoryStore: Block taskresult_28 stored as bytes in memory (estimated size 1834.4 KiB, free 361.0 MiB)
21/12/04 17:29:15 INFO BlockManagerInfo: Added taskresult_28 in memory on 10.0.2.15:40275 (size: 1834.4 KiB, free: 361.1 MiB)
21/12/04 17:29:15 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 1878403 bytes result sent via BlockManager)
21/12/04 17:29:15 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 77 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:15 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/12/04 17:29:15 INFO BlockManagerInfo: Removed taskresult_28 on 10.0.2.15:40275 in memory (size: 1834.4 KiB, free: 362.9 MiB)
21/12/04 17:29:15 INFO DAGScheduler: ResultStage 28 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.091 s
21/12/04 17:29:15 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/12/04 17:29:15 INFO DAGScheduler: Job 29 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.100106 s
21/12/04 17:29:15 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:15 INFO DAGScheduler: Got job 30 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:15 INFO DAGScheduler: Final stage: ResultStage 29 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:15 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:15 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:15 INFO DAGScheduler: Submitting ResultStage 29 (BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:15 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:29:15 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:29:15 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:15 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:15 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
21/12/04 17:29:15 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:15 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
21/12/04 17:29:15 INFO BlockManager: Found block input-0-1638619151400 locally
21/12/04 17:29:15 INFO MemoryStore: Block taskresult_29 stored as bytes in memory (estimated size 1834.4 KiB, free 361.0 MiB)
21/12/04 17:29:15 INFO BlockManagerInfo: Added taskresult_29 in memory on 10.0.2.15:40275 (size: 1834.4 KiB, free: 361.1 MiB)
21/12/04 17:29:15 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 1878403 bytes result sent via BlockManager)
21/12/04 17:29:15 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 76 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:15 INFO DAGScheduler: ResultStage 29 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.083 s
21/12/04 17:29:15 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:15 INFO BlockManagerInfo: Removed taskresult_29 on 10.0.2.15:40275 in memory (size: 1834.4 KiB, free: 362.9 MiB)
21/12/04 17:29:15 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/12/04 17:29:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
21/12/04 17:29:15 INFO DAGScheduler: Job 30 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.088443 s
21/12/04 17:29:15 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:15 INFO DAGScheduler: Got job 31 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:15 INFO DAGScheduler: Final stage: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:15 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:15 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:15 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[81] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:15 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 10.9 KiB, free 362.8 MiB)
21/12/04 17:29:15 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.8 MiB)
21/12/04 17:29:15 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:29:15 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[81] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:15 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
21/12/04 17:29:15 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 438821 bytes) taskResourceAssignments Map()
21/12/04 17:29:15 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
21/12/04 17:29:15 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 2363 bytes result sent to driver
21/12/04 17:29:15 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 27 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:15 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/12/04 17:29:15 INFO DAGScheduler: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0) finished in 0.042 s
21/12/04 17:29:15 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/12/04 17:29:15 INFO DAGScheduler: Job 31 finished: showString at NativeMethodAccessorImpl.java:0, took 0.063860 s
21/12/04 17:29:15 INFO JobScheduler: Finished job streaming job 1638619155000 ms.0 from job set of time 1638619155000 ms
21/12/04 17:29:15 INFO BlockRDD: Removing RDD 66 from persistence list
21/12/04 17:29:15 INFO JobScheduler: Total delay: 0.513 s for time 1638619155000 ms (execution: 0.507 s)
21/12/04 17:29:15 INFO BlockManager: Removing RDD 66
21/12/04 17:29:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[66] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619155000 ms
21/12/04 17:29:15 INFO ReceivedBlockTracker: Deleting batches: 1638619145000 ms
21/12/04 17:29:15 INFO InputInfoTracker: remove old batch metadata: 1638619145000 ms
21/12/04 17:29:15 INFO BlockManagerInfo: Removed input-0-1638619146400 on 10.0.2.15:40275 in memory (size: 1597.7 KiB, free: 364.5 MiB)
21/12/04 17:29:16 INFO MemoryStore: Block input-0-1638619156400 stored as values in memory (estimated size 1855.0 KiB, free 362.6 MiB)
21/12/04 17:29:16 INFO BlockManagerInfo: Added input-0-1638619156400 in memory on 10.0.2.15:40275 (size: 1855.0 KiB, free: 362.7 MiB)
21/12/04 17:29:16 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:29:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:16 WARN BlockManager: Block input-0-1638619156400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:16 INFO BlockGenerator: Pushed block input-0-1638619156400
21/12/04 17:29:16 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:16 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:16 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:16 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:16 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:29:20 INFO JobScheduler: Added jobs for time 1638619160000 ms
21/12/04 17:29:20 INFO JobScheduler: Starting job streaming job 1638619160000 ms.0 from job set of time 1638619160000 ms
21/12/04 17:29:20 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:20 INFO DAGScheduler: Got job 32 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:20 INFO DAGScheduler: Final stage: ResultStage 31 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:20 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:20 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:20 INFO DAGScheduler: Submitting ResultStage 31 (BlockRDD[82] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:20 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 1968.0 B, free 362.6 MiB)
21/12/04 17:29:20 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.6 MiB)
21/12/04 17:29:20 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:20 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (BlockRDD[82] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:20 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
21/12/04 17:29:20 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:20 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
21/12/04 17:29:20 INFO BlockManager: Found block input-0-1638619156400 locally
21/12/04 17:29:20 INFO MemoryStore: Block taskresult_31 stored as bytes in memory (estimated size 1864.8 KiB, free 360.8 MiB)
21/12/04 17:29:20 INFO BlockManagerInfo: Added taskresult_31 in memory on 10.0.2.15:40275 (size: 1864.8 KiB, free: 360.9 MiB)
21/12/04 17:29:20 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 1909582 bytes result sent via BlockManager)
21/12/04 17:29:20 INFO BlockManagerInfo: Removed taskresult_31 on 10.0.2.15:40275 in memory (size: 1864.8 KiB, free: 362.7 MiB)
21/12/04 17:29:20 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 89 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:20 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/12/04 17:29:20 INFO DAGScheduler: ResultStage 31 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.102 s
21/12/04 17:29:20 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
21/12/04 17:29:20 INFO DAGScheduler: Job 32 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.104667 s
21/12/04 17:29:20 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:20 INFO DAGScheduler: Got job 33 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:20 INFO DAGScheduler: Final stage: ResultStage 32 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:20 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:20 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:20 INFO DAGScheduler: Submitting ResultStage 32 (BlockRDD[82] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:20 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 1968.0 B, free 362.6 MiB)
21/12/04 17:29:20 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.6 MiB)
21/12/04 17:29:20 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:20 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (BlockRDD[82] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:20 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
21/12/04 17:29:20 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:20 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
21/12/04 17:29:20 INFO BlockManager: Found block input-0-1638619156400 locally
21/12/04 17:29:20 INFO MemoryStore: Block taskresult_32 stored as bytes in memory (estimated size 1864.9 KiB, free 360.8 MiB)
21/12/04 17:29:20 INFO BlockManagerInfo: Added taskresult_32 in memory on 10.0.2.15:40275 (size: 1864.9 KiB, free: 360.9 MiB)
21/12/04 17:29:20 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 1909625 bytes result sent via BlockManager)
21/12/04 17:29:20 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 57 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:20 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/12/04 17:29:20 INFO BlockManagerInfo: Removed taskresult_32 on 10.0.2.15:40275 in memory (size: 1864.9 KiB, free: 362.7 MiB)
21/12/04 17:29:20 INFO DAGScheduler: ResultStage 32 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.068 s
21/12/04 17:29:20 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/12/04 17:29:20 INFO DAGScheduler: Job 33 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.072531 s
21/12/04 17:29:20 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:20 INFO DAGScheduler: Got job 34 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:20 INFO DAGScheduler: Final stage: ResultStage 33 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:20 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:20 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:20 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[89] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:20 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 10.9 KiB, free 362.6 MiB)
21/12/04 17:29:20 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.6 MiB)
21/12/04 17:29:20 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:29:20 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[89] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:20 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
21/12/04 17:29:20 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 422113 bytes) taskResourceAssignments Map()
21/12/04 17:29:20 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
21/12/04 17:29:20 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 2287 bytes result sent to driver
21/12/04 17:29:20 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 31 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:20 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/12/04 17:29:20 INFO DAGScheduler: ResultStage 33 (showString at NativeMethodAccessorImpl.java:0) finished in 0.045 s
21/12/04 17:29:20 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
21/12/04 17:29:20 INFO DAGScheduler: Job 34 finished: showString at NativeMethodAccessorImpl.java:0, took 0.052134 s
21/12/04 17:29:20 INFO JobScheduler: Finished job streaming job 1638619160000 ms.0 from job set of time 1638619160000 ms
21/12/04 17:29:20 INFO JobScheduler: Total delay: 0.449 s for time 1638619160000 ms (execution: 0.444 s)
21/12/04 17:29:20 INFO BlockRDD: Removing RDD 74 from persistence list
21/12/04 17:29:20 INFO BlockManager: Removing RDD 74
21/12/04 17:29:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619160000 ms
21/12/04 17:29:20 INFO ReceivedBlockTracker: Deleting batches: 1638619150000 ms
21/12/04 17:29:20 INFO InputInfoTracker: remove old batch metadata: 1638619150000 ms
21/12/04 17:29:20 INFO BlockManagerInfo: Removed input-0-1638619151400 on 10.0.2.15:40275 in memory (size: 1824.6 KiB, free: 364.5 MiB)
21/12/04 17:29:21 INFO MemoryStore: Block input-0-1638619161400 stored as values in memory (estimated size 1632.6 KiB, free 362.8 MiB)
21/12/04 17:29:21 INFO BlockManagerInfo: Added input-0-1638619161400 in memory on 10.0.2.15:40275 (size: 1632.6 KiB, free: 362.9 MiB)
21/12/04 17:29:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:21 WARN BlockManager: Block input-0-1638619161400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:21 INFO BlockGenerator: Pushed block input-0-1638619161400
21/12/04 17:29:25 INFO JobScheduler: Added jobs for time 1638619165000 ms
21/12/04 17:29:25 INFO JobScheduler: Starting job streaming job 1638619165000 ms.0 from job set of time 1638619165000 ms
21/12/04 17:29:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:25 INFO DAGScheduler: Got job 35 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:25 INFO DAGScheduler: Final stage: ResultStage 34 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:25 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:25 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:25 INFO DAGScheduler: Submitting ResultStage 34 (BlockRDD[90] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:25 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:29:25 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:29:25 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:25 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (BlockRDD[90] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:25 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
21/12/04 17:29:25 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:25 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
21/12/04 17:29:25 INFO BlockManager: Found block input-0-1638619161400 locally
21/12/04 17:29:25 INFO MemoryStore: Block taskresult_34 stored as bytes in memory (estimated size 1641.4 KiB, free 361.2 MiB)
21/12/04 17:29:25 INFO BlockManagerInfo: Added taskresult_34 in memory on 10.0.2.15:40275 (size: 1641.4 KiB, free: 361.3 MiB)
21/12/04 17:29:25 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 1680775 bytes result sent via BlockManager)
21/12/04 17:29:25 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 67 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:25 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/12/04 17:29:25 INFO BlockManagerInfo: Removed taskresult_34 on 10.0.2.15:40275 in memory (size: 1641.4 KiB, free: 362.9 MiB)
21/12/04 17:29:25 INFO DAGScheduler: ResultStage 34 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.086 s
21/12/04 17:29:25 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/12/04 17:29:25 INFO DAGScheduler: Job 35 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.089706 s
21/12/04 17:29:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:25 INFO DAGScheduler: Got job 36 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:25 INFO DAGScheduler: Final stage: ResultStage 35 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:25 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:25 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:25 INFO DAGScheduler: Submitting ResultStage 35 (BlockRDD[90] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:25 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:29:25 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:29:25 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:25 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (BlockRDD[90] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:25 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
21/12/04 17:29:25 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:25 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
21/12/04 17:29:25 INFO BlockManager: Found block input-0-1638619161400 locally
21/12/04 17:29:25 INFO MemoryStore: Block taskresult_35 stored as bytes in memory (estimated size 1641.4 KiB, free 361.2 MiB)
21/12/04 17:29:25 INFO BlockManagerInfo: Added taskresult_35 in memory on 10.0.2.15:40275 (size: 1641.4 KiB, free: 361.3 MiB)
21/12/04 17:29:25 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 1680775 bytes result sent via BlockManager)
21/12/04 17:29:25 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 86 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:25 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/12/04 17:29:25 INFO BlockManagerInfo: Removed taskresult_35 on 10.0.2.15:40275 in memory (size: 1641.4 KiB, free: 362.9 MiB)
21/12/04 17:29:25 INFO DAGScheduler: ResultStage 35 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.105 s
21/12/04 17:29:25 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
21/12/04 17:29:25 INFO DAGScheduler: Job 36 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.113758 s
21/12/04 17:29:25 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:25 INFO DAGScheduler: Got job 37 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:25 INFO DAGScheduler: Final stage: ResultStage 36 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:25 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:25 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:25 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[97] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:25 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 10.9 KiB, free 362.7 MiB)
21/12/04 17:29:25 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.7 MiB)
21/12/04 17:29:25 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:25 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:29:25 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:25 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:29:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[97] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:25 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
21/12/04 17:29:25 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:25 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 504552 bytes) taskResourceAssignments Map()
21/12/04 17:29:25 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
21/12/04 17:29:25 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:25 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 2368 bytes result sent to driver
21/12/04 17:29:25 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 61 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:25 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/12/04 17:29:25 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:29:25 INFO DAGScheduler: ResultStage 36 (showString at NativeMethodAccessorImpl.java:0) finished in 0.129 s
21/12/04 17:29:25 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
21/12/04 17:29:25 INFO DAGScheduler: Job 37 finished: showString at NativeMethodAccessorImpl.java:0, took 0.140666 s
21/12/04 17:29:25 INFO JobScheduler: Finished job streaming job 1638619165000 ms.0 from job set of time 1638619165000 ms
21/12/04 17:29:25 INFO JobScheduler: Total delay: 0.607 s for time 1638619165000 ms (execution: 0.600 s)
21/12/04 17:29:25 INFO BlockRDD: Removing RDD 82 from persistence list
21/12/04 17:29:25 INFO BlockManager: Removing RDD 82
21/12/04 17:29:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[82] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619165000 ms
21/12/04 17:29:25 INFO ReceivedBlockTracker: Deleting batches: 1638619155000 ms
21/12/04 17:29:25 INFO InputInfoTracker: remove old batch metadata: 1638619155000 ms
21/12/04 17:29:25 INFO BlockManagerInfo: Removed input-0-1638619156400 on 10.0.2.15:40275 in memory (size: 1855.0 KiB, free: 364.7 MiB)
21/12/04 17:29:26 INFO MemoryStore: Block input-0-1638619166400 stored as values in memory (estimated size 1621.4 KiB, free 363.0 MiB)
21/12/04 17:29:26 INFO BlockManagerInfo: Added input-0-1638619166400 in memory on 10.0.2.15:40275 (size: 1621.4 KiB, free: 363.1 MiB)
21/12/04 17:29:26 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:26 WARN BlockManager: Block input-0-1638619166400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:26 INFO BlockGenerator: Pushed block input-0-1638619166400
21/12/04 17:29:30 INFO JobScheduler: Added jobs for time 1638619170000 ms
21/12/04 17:29:30 INFO JobScheduler: Starting job streaming job 1638619170000 ms.0 from job set of time 1638619170000 ms
21/12/04 17:29:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:30 INFO DAGScheduler: Got job 38 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:30 INFO DAGScheduler: Final stage: ResultStage 37 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:30 INFO DAGScheduler: Submitting ResultStage 37 (BlockRDD[98] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:30 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 1968.0 B, free 363.0 MiB)
21/12/04 17:29:30 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.0 MiB)
21/12/04 17:29:30 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:30 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (BlockRDD[98] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:30 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
21/12/04 17:29:30 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:30 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)
21/12/04 17:29:30 INFO BlockManager: Found block input-0-1638619166400 locally
21/12/04 17:29:30 INFO MemoryStore: Block taskresult_37 stored as bytes in memory (estimated size 1630.2 KiB, free 361.4 MiB)
21/12/04 17:29:30 INFO BlockManagerInfo: Added taskresult_37 in memory on 10.0.2.15:40275 (size: 1630.2 KiB, free: 361.5 MiB)
21/12/04 17:29:30 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 1669319 bytes result sent via BlockManager)
21/12/04 17:29:30 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 46 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:30 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/12/04 17:29:30 INFO BlockManagerInfo: Removed taskresult_37 on 10.0.2.15:40275 in memory (size: 1630.2 KiB, free: 363.1 MiB)
21/12/04 17:29:30 INFO DAGScheduler: ResultStage 37 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.056 s
21/12/04 17:29:30 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/12/04 17:29:30 INFO DAGScheduler: Job 38 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.060254 s
21/12/04 17:29:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:30 INFO DAGScheduler: Got job 39 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:30 INFO DAGScheduler: Final stage: ResultStage 38 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:30 INFO DAGScheduler: Submitting ResultStage 38 (BlockRDD[98] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:30 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 1968.0 B, free 363.0 MiB)
21/12/04 17:29:30 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.0 MiB)
21/12/04 17:29:30 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:29:30 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (BlockRDD[98] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:30 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
21/12/04 17:29:30 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:30 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)
21/12/04 17:29:30 INFO BlockManager: Found block input-0-1638619166400 locally
21/12/04 17:29:30 INFO MemoryStore: Block taskresult_38 stored as bytes in memory (estimated size 1630.2 KiB, free 361.4 MiB)
21/12/04 17:29:30 INFO BlockManagerInfo: Added taskresult_38 in memory on 10.0.2.15:40275 (size: 1630.2 KiB, free: 361.5 MiB)
21/12/04 17:29:30 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 1669319 bytes result sent via BlockManager)
21/12/04 17:29:30 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 68 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:30 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/12/04 17:29:30 INFO BlockManagerInfo: Removed taskresult_38 on 10.0.2.15:40275 in memory (size: 1630.2 KiB, free: 363.1 MiB)
21/12/04 17:29:30 INFO DAGScheduler: ResultStage 38 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.076 s
21/12/04 17:29:30 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
21/12/04 17:29:30 INFO DAGScheduler: Job 39 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.079744 s
21/12/04 17:29:30 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:30 INFO DAGScheduler: Got job 40 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:30 INFO DAGScheduler: Final stage: ResultStage 39 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:30 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[105] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:30 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 10.9 KiB, free 363.0 MiB)
21/12/04 17:29:30 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 363.0 MiB)
21/12/04 17:29:30 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.1 MiB)
21/12/04 17:29:30 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[105] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:30 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
21/12/04 17:29:30 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 409478 bytes) taskResourceAssignments Map()
21/12/04 17:29:30 INFO Executor: Running task 0.0 in stage 39.0 (TID 39)
21/12/04 17:29:30 INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 2362 bytes result sent to driver
21/12/04 17:29:30 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 43 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:30 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/12/04 17:29:30 INFO DAGScheduler: ResultStage 39 (showString at NativeMethodAccessorImpl.java:0) finished in 0.072 s
21/12/04 17:29:30 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/12/04 17:29:30 INFO DAGScheduler: Job 40 finished: showString at NativeMethodAccessorImpl.java:0, took 0.087890 s
21/12/04 17:29:30 INFO JobScheduler: Finished job streaming job 1638619170000 ms.0 from job set of time 1638619170000 ms
21/12/04 17:29:30 INFO JobScheduler: Total delay: 0.473 s for time 1638619170000 ms (execution: 0.465 s)
21/12/04 17:29:30 INFO BlockRDD: Removing RDD 90 from persistence list
21/12/04 17:29:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[90] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619170000 ms
21/12/04 17:29:30 INFO BlockManager: Removing RDD 90
21/12/04 17:29:30 INFO ReceivedBlockTracker: Deleting batches: 1638619160000 ms
21/12/04 17:29:30 INFO InputInfoTracker: remove old batch metadata: 1638619160000 ms
21/12/04 17:29:30 INFO BlockManagerInfo: Removed input-0-1638619161400 on 10.0.2.15:40275 in memory (size: 1632.6 KiB, free: 364.7 MiB)
21/12/04 17:29:31 INFO MemoryStore: Block input-0-1638619171400 stored as values in memory (estimated size 1990.3 KiB, free 362.6 MiB)
21/12/04 17:29:31 INFO BlockManagerInfo: Added input-0-1638619171400 in memory on 10.0.2.15:40275 (size: 1990.3 KiB, free: 362.7 MiB)
21/12/04 17:29:31 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:31 WARN BlockManager: Block input-0-1638619171400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:31 INFO BlockGenerator: Pushed block input-0-1638619171400
21/12/04 17:29:35 INFO JobScheduler: Starting job streaming job 1638619175000 ms.0 from job set of time 1638619175000 ms
21/12/04 17:29:35 INFO JobScheduler: Added jobs for time 1638619175000 ms
21/12/04 17:29:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:35 INFO DAGScheduler: Got job 41 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:35 INFO DAGScheduler: Final stage: ResultStage 40 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:35 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:35 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:35 INFO DAGScheduler: Submitting ResultStage 40 (BlockRDD[106] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:35 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 1968.0 B, free 362.6 MiB)
21/12/04 17:29:35 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.6 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:35 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (BlockRDD[106] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:35 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
21/12/04 17:29:35 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:35 INFO Executor: Running task 0.0 in stage 40.0 (TID 40)
21/12/04 17:29:35 INFO BlockManager: Found block input-0-1638619171400 locally
21/12/04 17:29:35 INFO MemoryStore: Block taskresult_40 stored as bytes in memory (estimated size 2000.8 KiB, free 360.7 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Added taskresult_40 in memory on 10.0.2.15:40275 (size: 2000.8 KiB, free: 360.8 MiB)
21/12/04 17:29:35 INFO Executor: Finished task 0.0 in stage 40.0 (TID 40). 2048859 bytes result sent via BlockManager)
21/12/04 17:29:35 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 89 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:35 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/12/04 17:29:35 INFO DAGScheduler: ResultStage 40 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.098 s
21/12/04 17:29:35 INFO BlockManagerInfo: Removed taskresult_40 on 10.0.2.15:40275 in memory (size: 2000.8 KiB, free: 362.7 MiB)
21/12/04 17:29:35 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/12/04 17:29:35 INFO DAGScheduler: Job 41 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.101921 s
21/12/04 17:29:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:35 INFO DAGScheduler: Got job 42 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:35 INFO DAGScheduler: Final stage: ResultStage 41 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:35 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:35 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:35 INFO DAGScheduler: Submitting ResultStage 41 (BlockRDD[106] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:35 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 1968.0 B, free 362.6 MiB)
21/12/04 17:29:35 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.6 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:35 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (BlockRDD[106] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:35 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
21/12/04 17:29:35 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:35 INFO Executor: Running task 0.0 in stage 41.0 (TID 41)
21/12/04 17:29:35 INFO BlockManager: Found block input-0-1638619171400 locally
21/12/04 17:29:35 INFO MemoryStore: Block taskresult_41 stored as bytes in memory (estimated size 2000.8 KiB, free 360.7 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Added taskresult_41 in memory on 10.0.2.15:40275 (size: 2000.8 KiB, free: 360.8 MiB)
21/12/04 17:29:35 INFO Executor: Finished task 0.0 in stage 41.0 (TID 41). 2048859 bytes result sent via BlockManager)
21/12/04 17:29:35 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 67 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:35 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/12/04 17:29:35 INFO DAGScheduler: ResultStage 41 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.076 s
21/12/04 17:29:35 INFO BlockManagerInfo: Removed taskresult_41 on 10.0.2.15:40275 in memory (size: 2000.8 KiB, free: 362.7 MiB)
21/12/04 17:29:35 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
21/12/04 17:29:35 INFO DAGScheduler: Job 42 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.079514 s
21/12/04 17:29:35 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:29:35 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:35 INFO DAGScheduler: Got job 43 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:35 INFO DAGScheduler: Final stage: ResultStage 42 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:35 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:35 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:35 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[113] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:35 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 10.9 KiB, free 362.7 MiB)
21/12/04 17:29:35 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.6 MiB)
21/12/04 17:29:35 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:29:35 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[113] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:35 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
21/12/04 17:29:35 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 528059 bytes) taskResourceAssignments Map()
21/12/04 17:29:35 INFO Executor: Running task 0.0 in stage 42.0 (TID 42)
21/12/04 17:29:35 INFO Executor: Finished task 0.0 in stage 42.0 (TID 42). 2478 bytes result sent to driver
21/12/04 17:29:35 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 38 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:35 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/12/04 17:29:35 INFO DAGScheduler: ResultStage 42 (showString at NativeMethodAccessorImpl.java:0) finished in 0.049 s
21/12/04 17:29:35 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/12/04 17:29:35 INFO DAGScheduler: Job 43 finished: showString at NativeMethodAccessorImpl.java:0, took 0.063653 s
21/12/04 17:29:35 INFO JobScheduler: Finished job streaming job 1638619175000 ms.0 from job set of time 1638619175000 ms
21/12/04 17:29:35 INFO JobScheduler: Total delay: 0.548 s for time 1638619175000 ms (execution: 0.529 s)
21/12/04 17:29:35 INFO BlockRDD: Removing RDD 98 from persistence list
21/12/04 17:29:35 INFO BlockManager: Removing RDD 98
21/12/04 17:29:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[98] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619175000 ms
21/12/04 17:29:35 INFO ReceivedBlockTracker: Deleting batches: 1638619165000 ms
21/12/04 17:29:35 INFO InputInfoTracker: remove old batch metadata: 1638619165000 ms
21/12/04 17:29:35 INFO BlockManagerInfo: Removed input-0-1638619166400 on 10.0.2.15:40275 in memory (size: 1621.4 KiB, free: 364.3 MiB)
21/12/04 17:29:36 INFO MemoryStore: Block input-0-1638619176400 stored as values in memory (estimated size 1747.1 KiB, free 362.5 MiB)
21/12/04 17:29:36 INFO BlockManagerInfo: Added input-0-1638619176400 in memory on 10.0.2.15:40275 (size: 1747.1 KiB, free: 362.6 MiB)
21/12/04 17:29:36 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:36 WARN BlockManager: Block input-0-1638619176400 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:36 INFO BlockGenerator: Pushed block input-0-1638619176400
21/12/04 17:29:40 INFO JobScheduler: Added jobs for time 1638619180000 ms
21/12/04 17:29:40 INFO JobScheduler: Starting job streaming job 1638619180000 ms.0 from job set of time 1638619180000 ms
21/12/04 17:29:40 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:40 INFO DAGScheduler: Got job 44 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:40 INFO DAGScheduler: Final stage: ResultStage 43 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:40 INFO DAGScheduler: Submitting ResultStage 43 (BlockRDD[114] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:40 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 1968.0 B, free 362.5 MiB)
21/12/04 17:29:40 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.5 MiB)
21/12/04 17:29:40 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.6 MiB)
21/12/04 17:29:40 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (BlockRDD[114] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:40 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
21/12/04 17:29:40 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 43) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:40 INFO Executor: Running task 0.0 in stage 43.0 (TID 43)
21/12/04 17:29:40 INFO BlockManager: Found block input-0-1638619176400 locally
21/12/04 17:29:40 INFO MemoryStore: Block taskresult_43 stored as bytes in memory (estimated size 1756.4 KiB, free 360.8 MiB)
21/12/04 17:29:40 INFO BlockManagerInfo: Added taskresult_43 in memory on 10.0.2.15:40275 (size: 1756.4 KiB, free: 360.9 MiB)
21/12/04 17:29:40 INFO Executor: Finished task 0.0 in stage 43.0 (TID 43). 1798595 bytes result sent via BlockManager)
21/12/04 17:29:40 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 43) in 50 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:40 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/12/04 17:29:40 INFO BlockManagerInfo: Removed taskresult_43 on 10.0.2.15:40275 in memory (size: 1756.4 KiB, free: 362.6 MiB)
21/12/04 17:29:40 INFO DAGScheduler: ResultStage 43 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.059 s
21/12/04 17:29:40 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
21/12/04 17:29:40 INFO DAGScheduler: Job 44 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.066435 s
21/12/04 17:29:40 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:40 INFO DAGScheduler: Got job 45 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:40 INFO DAGScheduler: Final stage: ResultStage 44 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:40 INFO DAGScheduler: Submitting ResultStage 44 (BlockRDD[114] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:40 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 1968.0 B, free 362.5 MiB)
21/12/04 17:29:40 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.5 MiB)
21/12/04 17:29:40 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.6 MiB)
21/12/04 17:29:40 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (BlockRDD[114] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:40 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
21/12/04 17:29:40 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:40 INFO Executor: Running task 0.0 in stage 44.0 (TID 44)
21/12/04 17:29:40 INFO BlockManager: Found block input-0-1638619176400 locally
21/12/04 17:29:40 INFO MemoryStore: Block taskresult_44 stored as bytes in memory (estimated size 1756.4 KiB, free 360.8 MiB)
21/12/04 17:29:40 INFO BlockManagerInfo: Added taskresult_44 in memory on 10.0.2.15:40275 (size: 1756.4 KiB, free: 360.9 MiB)
21/12/04 17:29:40 INFO Executor: Finished task 0.0 in stage 44.0 (TID 44). 1798595 bytes result sent via BlockManager)
21/12/04 17:29:40 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 66 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:40 INFO DAGScheduler: ResultStage 44 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.073 s
21/12/04 17:29:40 INFO BlockManagerInfo: Removed taskresult_44 on 10.0.2.15:40275 in memory (size: 1756.4 KiB, free: 362.6 MiB)
21/12/04 17:29:40 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:40 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/12/04 17:29:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/12/04 17:29:40 INFO DAGScheduler: Job 45 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.076393 s
21/12/04 17:29:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:40 INFO DAGScheduler: Got job 46 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:40 INFO DAGScheduler: Final stage: ResultStage 45 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:40 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[121] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:40 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 10.9 KiB, free 362.5 MiB)
21/12/04 17:29:40 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.5 MiB)
21/12/04 17:29:40 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.6 MiB)
21/12/04 17:29:40 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[121] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:40 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
21/12/04 17:29:40 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 453788 bytes) taskResourceAssignments Map()
21/12/04 17:29:40 INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
21/12/04 17:29:40 INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 2297 bytes result sent to driver
21/12/04 17:29:40 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 28 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:40 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/12/04 17:29:40 INFO DAGScheduler: ResultStage 45 (showString at NativeMethodAccessorImpl.java:0) finished in 0.041 s
21/12/04 17:29:40 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/12/04 17:29:40 INFO DAGScheduler: Job 46 finished: showString at NativeMethodAccessorImpl.java:0, took 0.047380 s
21/12/04 17:29:40 INFO JobScheduler: Finished job streaming job 1638619180000 ms.0 from job set of time 1638619180000 ms
21/12/04 17:29:40 INFO JobScheduler: Total delay: 0.426 s for time 1638619180000 ms (execution: 0.419 s)
21/12/04 17:29:40 INFO BlockRDD: Removing RDD 106 from persistence list
21/12/04 17:29:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[106] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619180000 ms
21/12/04 17:29:40 INFO BlockManager: Removing RDD 106
21/12/04 17:29:40 INFO ReceivedBlockTracker: Deleting batches: 1638619170000 ms
21/12/04 17:29:40 INFO BlockManagerInfo: Removed input-0-1638619171400 on 10.0.2.15:40275 in memory (size: 1990.3 KiB, free: 364.6 MiB)
21/12/04 17:29:40 INFO InputInfoTracker: remove old batch metadata: 1638619170000 ms
21/12/04 17:29:41 INFO MemoryStore: Block input-0-1638619181600 stored as values in memory (estimated size 1808.6 KiB, free 362.7 MiB)
21/12/04 17:29:41 INFO BlockManagerInfo: Added input-0-1638619181600 in memory on 10.0.2.15:40275 (size: 1808.6 KiB, free: 362.8 MiB)
21/12/04 17:29:41 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:41 WARN BlockManager: Block input-0-1638619181600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:41 INFO BlockGenerator: Pushed block input-0-1638619181600
21/12/04 17:29:45 INFO JobScheduler: Added jobs for time 1638619185000 ms
21/12/04 17:29:45 INFO JobScheduler: Starting job streaming job 1638619185000 ms.0 from job set of time 1638619185000 ms
21/12/04 17:29:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:45 INFO DAGScheduler: Got job 47 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:45 INFO DAGScheduler: Final stage: ResultStage 46 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:45 INFO DAGScheduler: Submitting ResultStage 46 (BlockRDD[122] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:45 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 1968.0 B, free 362.7 MiB)
21/12/04 17:29:45 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.7 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:29:45 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (BlockRDD[122] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:45 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
21/12/04 17:29:45 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:45 INFO Executor: Running task 0.0 in stage 46.0 (TID 46)
21/12/04 17:29:45 INFO BlockManager: Found block input-0-1638619181600 locally
21/12/04 17:29:45 INFO MemoryStore: Block taskresult_46 stored as bytes in memory (estimated size 1818.3 KiB, free 360.9 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Added taskresult_46 in memory on 10.0.2.15:40275 (size: 1818.3 KiB, free: 361.0 MiB)
21/12/04 17:29:45 INFO Executor: Finished task 0.0 in stage 46.0 (TID 46). 1861976 bytes result sent via BlockManager)
21/12/04 17:29:45 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 67 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:45 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/12/04 17:29:45 INFO DAGScheduler: ResultStage 46 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.078 s
21/12/04 17:29:45 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/12/04 17:29:45 INFO BlockManagerInfo: Removed taskresult_46 on 10.0.2.15:40275 in memory (size: 1818.3 KiB, free: 362.8 MiB)
21/12/04 17:29:45 INFO DAGScheduler: Job 47 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.086731 s
21/12/04 17:29:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:45 INFO DAGScheduler: Got job 48 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:45 INFO DAGScheduler: Final stage: ResultStage 47 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:45 INFO DAGScheduler: Submitting ResultStage 47 (BlockRDD[122] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:45 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 1968.0 B, free 362.7 MiB)
21/12/04 17:29:45 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.7 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:29:45 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (BlockRDD[122] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:45 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
21/12/04 17:29:45 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:45 INFO Executor: Running task 0.0 in stage 47.0 (TID 47)
21/12/04 17:29:45 INFO BlockManager: Found block input-0-1638619181600 locally
21/12/04 17:29:45 INFO MemoryStore: Block taskresult_47 stored as bytes in memory (estimated size 1818.3 KiB, free 360.9 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Added taskresult_47 in memory on 10.0.2.15:40275 (size: 1818.3 KiB, free: 361.0 MiB)
21/12/04 17:29:45 INFO Executor: Finished task 0.0 in stage 47.0 (TID 47). 1861976 bytes result sent via BlockManager)
21/12/04 17:29:45 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 62 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:45 INFO DAGScheduler: ResultStage 47 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.079 s
21/12/04 17:29:45 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/12/04 17:29:45 INFO BlockManagerInfo: Removed taskresult_47 on 10.0.2.15:40275 in memory (size: 1818.3 KiB, free: 362.8 MiB)
21/12/04 17:29:45 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/12/04 17:29:45 INFO DAGScheduler: Job 48 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.086179 s
21/12/04 17:29:45 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.8 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 362.8 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.8 MiB)
21/12/04 17:29:45 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/12/04 17:29:45 INFO DAGScheduler: Got job 49 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:29:45 INFO DAGScheduler: Final stage: ResultStage 48 (showString at NativeMethodAccessorImpl.java:0)
21/12/04 17:29:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:45 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[129] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:45 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 10.9 KiB, free 362.7 MiB)
21/12/04 17:29:45 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.7 MiB)
21/12/04 17:29:45 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.8 MiB)
21/12/04 17:29:45 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[129] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:45 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
21/12/04 17:29:45 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 48) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 638405 bytes) taskResourceAssignments Map()
21/12/04 17:29:45 INFO Executor: Running task 0.0 in stage 48.0 (TID 48)
21/12/04 17:29:45 INFO Executor: Finished task 0.0 in stage 48.0 (TID 48). 2312 bytes result sent to driver
21/12/04 17:29:45 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 48) in 29 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:45 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/12/04 17:29:45 INFO DAGScheduler: ResultStage 48 (showString at NativeMethodAccessorImpl.java:0) finished in 0.037 s
21/12/04 17:29:45 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/12/04 17:29:45 INFO DAGScheduler: Job 49 finished: showString at NativeMethodAccessorImpl.java:0, took 0.044964 s
21/12/04 17:29:45 INFO JobScheduler: Finished job streaming job 1638619185000 ms.0 from job set of time 1638619185000 ms
21/12/04 17:29:45 INFO JobScheduler: Total delay: 0.483 s for time 1638619185000 ms (execution: 0.468 s)
21/12/04 17:29:45 INFO BlockRDD: Removing RDD 114 from persistence list
21/12/04 17:29:45 INFO BlockManager: Removing RDD 114
21/12/04 17:29:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[114] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619185000 ms
21/12/04 17:29:45 INFO ReceivedBlockTracker: Deleting batches: 1638619175000 ms
21/12/04 17:29:45 INFO InputInfoTracker: remove old batch metadata: 1638619175000 ms
21/12/04 17:29:45 INFO BlockManagerInfo: Removed input-0-1638619176400 on 10.0.2.15:40275 in memory (size: 1747.1 KiB, free: 364.5 MiB)
21/12/04 17:29:46 INFO MemoryStore: Block input-0-1638619186600 stored as values in memory (estimated size 1541.2 KiB, free 362.9 MiB)
21/12/04 17:29:46 INFO BlockManagerInfo: Added input-0-1638619186600 in memory on 10.0.2.15:40275 (size: 1541.2 KiB, free: 363.0 MiB)
21/12/04 17:29:46 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:46 WARN BlockManager: Block input-0-1638619186600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:46 INFO BlockGenerator: Pushed block input-0-1638619186600
21/12/04 17:29:50 INFO JobScheduler: Added jobs for time 1638619190000 ms
21/12/04 17:29:50 INFO JobScheduler: Starting job streaming job 1638619190000 ms.0 from job set of time 1638619190000 ms
21/12/04 17:29:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:50 INFO DAGScheduler: Got job 50 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:50 INFO DAGScheduler: Final stage: ResultStage 49 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:50 INFO DAGScheduler: Submitting ResultStage 49 (BlockRDD[130] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:50 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:29:50 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:29:50 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:29:50 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (BlockRDD[130] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:50 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
21/12/04 17:29:50 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 49) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:50 INFO Executor: Running task 0.0 in stage 49.0 (TID 49)
21/12/04 17:29:50 INFO BlockManager: Found block input-0-1638619186600 locally
21/12/04 17:29:50 INFO MemoryStore: Block taskresult_49 stored as bytes in memory (estimated size 1549.5 KiB, free 361.4 MiB)
21/12/04 17:29:50 INFO BlockManagerInfo: Added taskresult_49 in memory on 10.0.2.15:40275 (size: 1549.5 KiB, free: 361.5 MiB)
21/12/04 17:29:50 INFO Executor: Finished task 0.0 in stage 49.0 (TID 49). 1586725 bytes result sent via BlockManager)
21/12/04 17:29:50 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 49) in 63 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:50 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/12/04 17:29:50 INFO DAGScheduler: ResultStage 49 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.077 s
21/12/04 17:29:50 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/12/04 17:29:50 INFO DAGScheduler: Job 50 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.084573 s
21/12/04 17:29:50 INFO BlockManagerInfo: Removed taskresult_49 on 10.0.2.15:40275 in memory (size: 1549.5 KiB, free: 363.0 MiB)
21/12/04 17:29:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:50 INFO DAGScheduler: Got job 51 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:50 INFO DAGScheduler: Final stage: ResultStage 50 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:50 INFO DAGScheduler: Submitting ResultStage 50 (BlockRDD[130] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:50 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:29:50 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:29:50 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:29:50 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (BlockRDD[130] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:50 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
21/12/04 17:29:50 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 50) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:50 INFO Executor: Running task 0.0 in stage 50.0 (TID 50)
21/12/04 17:29:50 INFO BlockManager: Found block input-0-1638619186600 locally
21/12/04 17:29:50 INFO MemoryStore: Block taskresult_50 stored as bytes in memory (estimated size 1549.5 KiB, free 361.4 MiB)
21/12/04 17:29:50 INFO BlockManagerInfo: Added taskresult_50 in memory on 10.0.2.15:40275 (size: 1549.5 KiB, free: 361.5 MiB)
21/12/04 17:29:50 INFO Executor: Finished task 0.0 in stage 50.0 (TID 50). 1586725 bytes result sent via BlockManager)
21/12/04 17:29:50 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 50) in 54 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:50 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/12/04 17:29:50 INFO BlockManagerInfo: Removed taskresult_50 on 10.0.2.15:40275 in memory (size: 1549.5 KiB, free: 363.0 MiB)
21/12/04 17:29:50 INFO DAGScheduler: ResultStage 50 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.069 s
21/12/04 17:29:50 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/12/04 17:29:50 INFO DAGScheduler: Job 51 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.075839 s
21/12/04 17:29:50 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:29:50 INFO DAGScheduler: Got job 52 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:29:50 INFO DAGScheduler: Final stage: ResultStage 51 (showString at <unknown>:0)
21/12/04 17:29:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:50 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[137] at showString at <unknown>:0), which has no missing parents
21/12/04 17:29:50 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:29:50 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.9 MiB)
21/12/04 17:29:50 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:29:50 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[137] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:50 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
21/12/04 17:29:50 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 51) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 352416 bytes) taskResourceAssignments Map()
21/12/04 17:29:50 INFO Executor: Running task 0.0 in stage 51.0 (TID 51)
21/12/04 17:29:50 INFO Executor: Finished task 0.0 in stage 51.0 (TID 51). 2433 bytes result sent to driver
21/12/04 17:29:50 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 51) in 92 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:50 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/12/04 17:29:50 INFO DAGScheduler: ResultStage 51 (showString at <unknown>:0) finished in 0.115 s
21/12/04 17:29:50 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/12/04 17:29:50 INFO DAGScheduler: Job 52 finished: showString at <unknown>:0, took 0.136667 s
21/12/04 17:29:50 INFO JobScheduler: Finished job streaming job 1638619190000 ms.0 from job set of time 1638619190000 ms
21/12/04 17:29:50 INFO JobScheduler: Total delay: 0.538 s for time 1638619190000 ms (execution: 0.529 s)
21/12/04 17:29:50 INFO BlockRDD: Removing RDD 122 from persistence list
21/12/04 17:29:50 INFO BlockManager: Removing RDD 122
21/12/04 17:29:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[122] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619190000 ms
21/12/04 17:29:50 INFO ReceivedBlockTracker: Deleting batches: 1638619180000 ms
21/12/04 17:29:50 INFO InputInfoTracker: remove old batch metadata: 1638619180000 ms
21/12/04 17:29:50 INFO BlockManagerInfo: Removed input-0-1638619181600 on 10.0.2.15:40275 in memory (size: 1808.6 KiB, free: 364.8 MiB)
21/12/04 17:29:51 INFO MemoryStore: Block input-0-1638619191600 stored as values in memory (estimated size 1591.3 KiB, free 363.1 MiB)
21/12/04 17:29:51 INFO BlockManagerInfo: Added input-0-1638619191600 in memory on 10.0.2.15:40275 (size: 1591.3 KiB, free: 363.2 MiB)
21/12/04 17:29:51 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:51 WARN BlockManager: Block input-0-1638619191600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:51 INFO BlockGenerator: Pushed block input-0-1638619191600
21/12/04 17:29:55 INFO JobScheduler: Added jobs for time 1638619195000 ms
21/12/04 17:29:55 INFO JobScheduler: Starting job streaming job 1638619195000 ms.0 from job set of time 1638619195000 ms
21/12/04 17:29:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:55 INFO DAGScheduler: Got job 53 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:55 INFO DAGScheduler: Final stage: ResultStage 52 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:55 INFO DAGScheduler: Submitting ResultStage 52 (BlockRDD[138] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:55 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 1968.0 B, free 363.1 MiB)
21/12/04 17:29:55 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.1 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:29:55 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (BlockRDD[138] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:55 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
21/12/04 17:29:55 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 52) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:55 INFO Executor: Running task 0.0 in stage 52.0 (TID 52)
21/12/04 17:29:55 INFO BlockManager: Found block input-0-1638619191600 locally
21/12/04 17:29:55 INFO MemoryStore: Block taskresult_52 stored as bytes in memory (estimated size 1599.9 KiB, free 361.5 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Added taskresult_52 in memory on 10.0.2.15:40275 (size: 1599.9 KiB, free: 361.6 MiB)
21/12/04 17:29:55 INFO Executor: Finished task 0.0 in stage 52.0 (TID 52). 1638323 bytes result sent via BlockManager)
21/12/04 17:29:55 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 52) in 55 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:55 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/12/04 17:29:55 INFO DAGScheduler: ResultStage 52 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.061 s
21/12/04 17:29:55 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/12/04 17:29:55 INFO DAGScheduler: Job 53 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.064578 s
21/12/04 17:29:55 INFO BlockManagerInfo: Removed taskresult_52 on 10.0.2.15:40275 in memory (size: 1599.9 KiB, free: 363.2 MiB)
21/12/04 17:29:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:29:55 INFO DAGScheduler: Got job 54 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:29:55 INFO DAGScheduler: Final stage: ResultStage 53 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:29:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:55 INFO DAGScheduler: Submitting ResultStage 53 (BlockRDD[138] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:29:55 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 1968.0 B, free 363.1 MiB)
21/12/04 17:29:55 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.1 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:29:55 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (BlockRDD[138] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:55 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
21/12/04 17:29:55 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 53) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:29:55 INFO Executor: Running task 0.0 in stage 53.0 (TID 53)
21/12/04 17:29:55 INFO BlockManager: Found block input-0-1638619191600 locally
21/12/04 17:29:55 INFO MemoryStore: Block taskresult_53 stored as bytes in memory (estimated size 1599.9 KiB, free 361.5 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Added taskresult_53 in memory on 10.0.2.15:40275 (size: 1599.9 KiB, free: 361.6 MiB)
21/12/04 17:29:55 INFO Executor: Finished task 0.0 in stage 53.0 (TID 53). 1638323 bytes result sent via BlockManager)
21/12/04 17:29:55 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 53) in 66 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:55 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/12/04 17:29:55 INFO DAGScheduler: ResultStage 53 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.095 s
21/12/04 17:29:55 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/12/04 17:29:55 INFO DAGScheduler: Job 54 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.099470 s
21/12/04 17:29:55 INFO BlockManagerInfo: Removed taskresult_53 on 10.0.2.15:40275 in memory (size: 1599.9 KiB, free: 363.2 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.2 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.2 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:29:55 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:29:55 INFO DAGScheduler: Got job 55 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:29:55 INFO DAGScheduler: Final stage: ResultStage 54 (showString at <unknown>:0)
21/12/04 17:29:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:29:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:29:55 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[145] at showString at <unknown>:0), which has no missing parents
21/12/04 17:29:55 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 10.9 KiB, free 363.1 MiB)
21/12/04 17:29:55 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 363.1 MiB)
21/12/04 17:29:55 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.2 MiB)
21/12/04 17:29:55 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1388
21/12/04 17:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[145] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:29:55 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
21/12/04 17:29:55 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 54) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 370613 bytes) taskResourceAssignments Map()
21/12/04 17:29:55 INFO Executor: Running task 0.0 in stage 54.0 (TID 54)
21/12/04 17:29:55 INFO Executor: Finished task 0.0 in stage 54.0 (TID 54). 2305 bytes result sent to driver
21/12/04 17:29:55 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 54) in 25 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:29:55 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/12/04 17:29:55 INFO DAGScheduler: ResultStage 54 (showString at <unknown>:0) finished in 0.043 s
21/12/04 17:29:55 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:29:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/12/04 17:29:55 INFO DAGScheduler: Job 55 finished: showString at <unknown>:0, took 0.052894 s
21/12/04 17:29:55 INFO JobScheduler: Finished job streaming job 1638619195000 ms.0 from job set of time 1638619195000 ms
21/12/04 17:29:55 INFO JobScheduler: Total delay: 0.483 s for time 1638619195000 ms (execution: 0.478 s)
21/12/04 17:29:55 INFO BlockRDD: Removing RDD 130 from persistence list
21/12/04 17:29:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[130] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619195000 ms
21/12/04 17:29:55 INFO ReceivedBlockTracker: Deleting batches: 1638619185000 ms
21/12/04 17:29:55 INFO InputInfoTracker: remove old batch metadata: 1638619185000 ms
21/12/04 17:29:55 INFO BlockManager: Removing RDD 130
21/12/04 17:29:55 INFO BlockManagerInfo: Removed input-0-1638619186600 on 10.0.2.15:40275 in memory (size: 1541.2 KiB, free: 364.7 MiB)
21/12/04 17:29:56 INFO MemoryStore: Block input-0-1638619196600 stored as values in memory (estimated size 1525.1 KiB, free 363.1 MiB)
21/12/04 17:29:56 INFO BlockManagerInfo: Added input-0-1638619196600 in memory on 10.0.2.15:40275 (size: 1525.1 KiB, free: 363.2 MiB)
21/12/04 17:29:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:29:56 WARN BlockManager: Block input-0-1638619196600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:29:56 INFO BlockGenerator: Pushed block input-0-1638619196600
21/12/04 17:30:00 INFO JobScheduler: Added jobs for time 1638619200000 ms
21/12/04 17:30:00 INFO JobScheduler: Starting job streaming job 1638619200000 ms.0 from job set of time 1638619200000 ms
21/12/04 17:30:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:00 INFO DAGScheduler: Got job 56 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:00 INFO DAGScheduler: Final stage: ResultStage 55 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:00 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:00 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:00 INFO DAGScheduler: Submitting ResultStage 55 (BlockRDD[146] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:00 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 1968.0 B, free 363.1 MiB)
21/12/04 17:30:00 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.1 MiB)
21/12/04 17:30:00 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:30:00 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (BlockRDD[146] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:00 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
21/12/04 17:30:00 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:00 INFO Executor: Running task 0.0 in stage 55.0 (TID 55)
21/12/04 17:30:00 INFO BlockManager: Found block input-0-1638619196600 locally
21/12/04 17:30:00 INFO MemoryStore: Block taskresult_55 stored as bytes in memory (estimated size 1533.4 KiB, free 361.6 MiB)
21/12/04 17:30:00 INFO BlockManagerInfo: Added taskresult_55 in memory on 10.0.2.15:40275 (size: 1533.4 KiB, free: 361.7 MiB)
21/12/04 17:30:00 INFO Executor: Finished task 0.0 in stage 55.0 (TID 55). 1570173 bytes result sent via BlockManager)
21/12/04 17:30:00 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 110 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:00 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/12/04 17:30:00 INFO BlockManagerInfo: Removed taskresult_55 on 10.0.2.15:40275 in memory (size: 1533.4 KiB, free: 363.2 MiB)
21/12/04 17:30:00 INFO DAGScheduler: ResultStage 55 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.126 s
21/12/04 17:30:00 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/12/04 17:30:00 INFO DAGScheduler: Job 56 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.138601 s
21/12/04 17:30:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:00 INFO DAGScheduler: Got job 57 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:00 INFO DAGScheduler: Final stage: ResultStage 56 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:00 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:00 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:00 INFO DAGScheduler: Submitting ResultStage 56 (BlockRDD[146] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:00 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 1968.0 B, free 363.1 MiB)
21/12/04 17:30:00 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.1 MiB)
21/12/04 17:30:00 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.2 MiB)
21/12/04 17:30:00 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (BlockRDD[146] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:00 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
21/12/04 17:30:00 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 56) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:00 INFO Executor: Running task 0.0 in stage 56.0 (TID 56)
21/12/04 17:30:00 INFO BlockManager: Found block input-0-1638619196600 locally
21/12/04 17:30:00 INFO MemoryStore: Block taskresult_56 stored as bytes in memory (estimated size 1533.4 KiB, free 361.6 MiB)
21/12/04 17:30:00 INFO BlockManagerInfo: Added taskresult_56 in memory on 10.0.2.15:40275 (size: 1533.4 KiB, free: 361.7 MiB)
21/12/04 17:30:00 INFO Executor: Finished task 0.0 in stage 56.0 (TID 56). 1570173 bytes result sent via BlockManager)
21/12/04 17:30:00 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 56) in 93 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:00 INFO BlockManagerInfo: Removed taskresult_56 on 10.0.2.15:40275 in memory (size: 1533.4 KiB, free: 363.2 MiB)
21/12/04 17:30:00 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/12/04 17:30:00 INFO DAGScheduler: ResultStage 56 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.117 s
21/12/04 17:30:00 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
21/12/04 17:30:00 INFO DAGScheduler: Job 57 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.152039 s
21/12/04 17:30:00 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:00 INFO DAGScheduler: Got job 58 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:00 INFO DAGScheduler: Final stage: ResultStage 57 (showString at <unknown>:0)
21/12/04 17:30:00 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:00 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:00 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[153] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:00 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 10.9 KiB, free 363.1 MiB)
21/12/04 17:30:00 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 363.1 MiB)
21/12/04 17:30:00 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.2 MiB)
21/12/04 17:30:00 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[153] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:00 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
21/12/04 17:30:00 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 57) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 415365 bytes) taskResourceAssignments Map()
21/12/04 17:30:00 INFO Executor: Running task 0.0 in stage 57.0 (TID 57)
21/12/04 17:30:00 INFO Executor: Finished task 0.0 in stage 57.0 (TID 57). 2243 bytes result sent to driver
21/12/04 17:30:00 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 57) in 70 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:00 INFO DAGScheduler: ResultStage 57 (showString at <unknown>:0) finished in 0.087 s
21/12/04 17:30:00 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:00 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/12/04 17:30:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/12/04 17:30:00 INFO DAGScheduler: Job 58 finished: showString at <unknown>:0, took 0.102273 s
21/12/04 17:30:00 INFO JobScheduler: Finished job streaming job 1638619200000 ms.0 from job set of time 1638619200000 ms
21/12/04 17:30:00 INFO JobScheduler: Total delay: 0.862 s for time 1638619200000 ms (execution: 0.856 s)
21/12/04 17:30:00 INFO BlockRDD: Removing RDD 138 from persistence list
21/12/04 17:30:00 INFO BlockManager: Removing RDD 138
21/12/04 17:30:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[138] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619200000 ms
21/12/04 17:30:00 INFO ReceivedBlockTracker: Deleting batches: 1638619190000 ms
21/12/04 17:30:00 INFO InputInfoTracker: remove old batch metadata: 1638619190000 ms
21/12/04 17:30:00 INFO BlockManagerInfo: Removed input-0-1638619191600 on 10.0.2.15:40275 in memory (size: 1591.3 KiB, free: 364.8 MiB)
21/12/04 17:30:01 INFO MemoryStore: Block input-0-1638619201600 stored as values in memory (estimated size 1797.6 KiB, free 362.9 MiB)
21/12/04 17:30:01 INFO BlockManagerInfo: Added input-0-1638619201600 in memory on 10.0.2.15:40275 (size: 1797.6 KiB, free: 363.0 MiB)
21/12/04 17:30:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:01 WARN BlockManager: Block input-0-1638619201600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:01 INFO BlockGenerator: Pushed block input-0-1638619201600
21/12/04 17:30:05 INFO JobScheduler: Added jobs for time 1638619205000 ms
21/12/04 17:30:05 INFO JobScheduler: Starting job streaming job 1638619205000 ms.0 from job set of time 1638619205000 ms
21/12/04 17:30:05 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:05 INFO DAGScheduler: Got job 59 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:05 INFO DAGScheduler: Final stage: ResultStage 58 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:05 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:05 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:05 INFO DAGScheduler: Submitting ResultStage 58 (BlockRDD[154] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:05 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:05 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:05 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (BlockRDD[154] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:05 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
21/12/04 17:30:05 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 58) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:05 INFO Executor: Running task 0.0 in stage 58.0 (TID 58)
21/12/04 17:30:05 INFO BlockManager: Found block input-0-1638619201600 locally
21/12/04 17:30:05 INFO MemoryStore: Block taskresult_58 stored as bytes in memory (estimated size 1807.2 KiB, free 361.1 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Added taskresult_58 in memory on 10.0.2.15:40275 (size: 1807.2 KiB, free: 361.2 MiB)
21/12/04 17:30:05 INFO Executor: Finished task 0.0 in stage 58.0 (TID 58). 1850570 bytes result sent via BlockManager)
21/12/04 17:30:05 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 58) in 93 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:05 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/12/04 17:30:05 INFO DAGScheduler: ResultStage 58 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.113 s
21/12/04 17:30:05 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/12/04 17:30:05 INFO DAGScheduler: Job 59 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.127144 s
21/12/04 17:30:05 INFO BlockManagerInfo: Removed taskresult_58 on 10.0.2.15:40275 in memory (size: 1807.2 KiB, free: 363.0 MiB)
21/12/04 17:30:05 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:05 INFO DAGScheduler: Got job 60 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:05 INFO DAGScheduler: Final stage: ResultStage 59 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:05 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:05 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:05 INFO DAGScheduler: Submitting ResultStage 59 (BlockRDD[154] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:05 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:05 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:05 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (BlockRDD[154] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:05 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
21/12/04 17:30:05 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 59) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:05 INFO Executor: Running task 0.0 in stage 59.0 (TID 59)
21/12/04 17:30:05 INFO BlockManager: Found block input-0-1638619201600 locally
21/12/04 17:30:05 INFO MemoryStore: Block taskresult_59 stored as bytes in memory (estimated size 1807.2 KiB, free 361.1 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Added taskresult_59 in memory on 10.0.2.15:40275 (size: 1807.2 KiB, free: 361.2 MiB)
21/12/04 17:30:05 INFO Executor: Finished task 0.0 in stage 59.0 (TID 59). 1850570 bytes result sent via BlockManager)
21/12/04 17:30:05 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 59) in 104 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:05 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/12/04 17:30:05 INFO BlockManagerInfo: Removed taskresult_59 on 10.0.2.15:40275 in memory (size: 1807.2 KiB, free: 363.0 MiB)
21/12/04 17:30:05 INFO DAGScheduler: ResultStage 59 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.134 s
21/12/04 17:30:05 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
21/12/04 17:30:05 INFO DAGScheduler: Job 60 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.143795 s
21/12/04 17:30:05 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:05 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:05 INFO DAGScheduler: Got job 61 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:05 INFO DAGScheduler: Final stage: ResultStage 60 (showString at <unknown>:0)
21/12/04 17:30:05 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:05 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:05 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[161] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:05 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:30:05 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.9 MiB)
21/12/04 17:30:05 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:05 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[161] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:05 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
21/12/04 17:30:05 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 60) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 404536 bytes) taskResourceAssignments Map()
21/12/04 17:30:05 INFO Executor: Running task 0.0 in stage 60.0 (TID 60)
21/12/04 17:30:05 INFO Executor: Finished task 0.0 in stage 60.0 (TID 60). 2366 bytes result sent to driver
21/12/04 17:30:05 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 60) in 46 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:05 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/12/04 17:30:05 INFO DAGScheduler: ResultStage 60 (showString at <unknown>:0) finished in 0.077 s
21/12/04 17:30:05 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/12/04 17:30:05 INFO DAGScheduler: Job 61 finished: showString at <unknown>:0, took 0.097411 s
21/12/04 17:30:05 INFO JobScheduler: Finished job streaming job 1638619205000 ms.0 from job set of time 1638619205000 ms
21/12/04 17:30:05 INFO JobScheduler: Total delay: 0.806 s for time 1638619205000 ms (execution: 0.792 s)
21/12/04 17:30:05 INFO BlockRDD: Removing RDD 146 from persistence list
21/12/04 17:30:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[146] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619205000 ms
21/12/04 17:30:05 INFO BlockManager: Removing RDD 146
21/12/04 17:30:05 INFO ReceivedBlockTracker: Deleting batches: 1638619195000 ms
21/12/04 17:30:05 INFO InputInfoTracker: remove old batch metadata: 1638619195000 ms
21/12/04 17:30:05 INFO BlockManagerInfo: Removed input-0-1638619196600 on 10.0.2.15:40275 in memory (size: 1525.1 KiB, free: 364.5 MiB)
21/12/04 17:30:06 INFO MemoryStore: Block input-0-1638619206600 stored as values in memory (estimated size 1601.2 KiB, free 362.9 MiB)
21/12/04 17:30:06 INFO BlockManagerInfo: Added input-0-1638619206600 in memory on 10.0.2.15:40275 (size: 1601.2 KiB, free: 362.9 MiB)
21/12/04 17:30:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:06 WARN BlockManager: Block input-0-1638619206600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:06 INFO BlockGenerator: Pushed block input-0-1638619206600
21/12/04 17:30:10 INFO JobScheduler: Added jobs for time 1638619210000 ms
21/12/04 17:30:10 INFO JobScheduler: Starting job streaming job 1638619210000 ms.0 from job set of time 1638619210000 ms
21/12/04 17:30:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:10 INFO DAGScheduler: Got job 62 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:10 INFO DAGScheduler: Final stage: ResultStage 61 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:10 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:10 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:10 INFO DAGScheduler: Submitting ResultStage 61 (BlockRDD[162] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:10 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:10 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:10 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:30:10 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (BlockRDD[162] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:10 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
21/12/04 17:30:10 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 61) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:10 INFO Executor: Running task 0.0 in stage 61.0 (TID 61)
21/12/04 17:30:10 INFO BlockManager: Found block input-0-1638619206600 locally
21/12/04 17:30:10 INFO MemoryStore: Block taskresult_61 stored as bytes in memory (estimated size 1609.8 KiB, free 361.3 MiB)
21/12/04 17:30:10 INFO BlockManagerInfo: Added taskresult_61 in memory on 10.0.2.15:40275 (size: 1609.8 KiB, free: 361.4 MiB)
21/12/04 17:30:10 INFO Executor: Finished task 0.0 in stage 61.0 (TID 61). 1648456 bytes result sent via BlockManager)
21/12/04 17:30:10 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 61) in 80 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:10 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/12/04 17:30:10 INFO DAGScheduler: ResultStage 61 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.110 s
21/12/04 17:30:10 INFO BlockManagerInfo: Removed taskresult_61 on 10.0.2.15:40275 in memory (size: 1609.8 KiB, free: 362.9 MiB)
21/12/04 17:30:10 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/12/04 17:30:10 INFO DAGScheduler: Job 62 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.131147 s
21/12/04 17:30:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:10 INFO DAGScheduler: Got job 63 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:10 INFO DAGScheduler: Final stage: ResultStage 62 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:10 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:10 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:10 INFO DAGScheduler: Submitting ResultStage 62 (BlockRDD[162] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:10 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:10 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:10 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:30:10 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (BlockRDD[162] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:10 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
21/12/04 17:30:10 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 62) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:10 INFO Executor: Running task 0.0 in stage 62.0 (TID 62)
21/12/04 17:30:10 INFO BlockManager: Found block input-0-1638619206600 locally
21/12/04 17:30:10 INFO MemoryStore: Block taskresult_62 stored as bytes in memory (estimated size 1609.9 KiB, free 361.3 MiB)
21/12/04 17:30:10 INFO BlockManagerInfo: Added taskresult_62 in memory on 10.0.2.15:40275 (size: 1609.9 KiB, free: 361.4 MiB)
21/12/04 17:30:10 INFO Executor: Finished task 0.0 in stage 62.0 (TID 62). 1648499 bytes result sent via BlockManager)
21/12/04 17:30:10 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 62) in 86 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:10 INFO DAGScheduler: ResultStage 62 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.105 s
21/12/04 17:30:10 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:10 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/12/04 17:30:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
21/12/04 17:30:10 INFO BlockManagerInfo: Removed taskresult_62 on 10.0.2.15:40275 in memory (size: 1609.9 KiB, free: 362.9 MiB)
21/12/04 17:30:10 INFO DAGScheduler: Job 63 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.112421 s
21/12/04 17:30:10 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:10 INFO DAGScheduler: Got job 64 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:10 INFO DAGScheduler: Final stage: ResultStage 63 (showString at <unknown>:0)
21/12/04 17:30:10 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:10 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:10 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[169] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:10 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 10.9 KiB, free 362.8 MiB)
21/12/04 17:30:10 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.8 MiB)
21/12/04 17:30:10 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:30:10 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[169] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:10 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
21/12/04 17:30:10 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 63) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 349884 bytes) taskResourceAssignments Map()
21/12/04 17:30:10 INFO Executor: Running task 0.0 in stage 63.0 (TID 63)
21/12/04 17:30:10 INFO Executor: Finished task 0.0 in stage 63.0 (TID 63). 2354 bytes result sent to driver
21/12/04 17:30:10 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 63) in 77 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:10 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/12/04 17:30:10 INFO DAGScheduler: ResultStage 63 (showString at <unknown>:0) finished in 0.104 s
21/12/04 17:30:10 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/12/04 17:30:10 INFO DAGScheduler: Job 64 finished: showString at <unknown>:0, took 0.122153 s
21/12/04 17:30:10 INFO JobScheduler: Finished job streaming job 1638619210000 ms.0 from job set of time 1638619210000 ms
21/12/04 17:30:10 INFO BlockRDD: Removing RDD 154 from persistence list
21/12/04 17:30:10 INFO JobScheduler: Total delay: 0.692 s for time 1638619210000 ms (execution: 0.687 s)
21/12/04 17:30:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[154] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619210000 ms
21/12/04 17:30:10 INFO ReceivedBlockTracker: Deleting batches: 1638619200000 ms
21/12/04 17:30:10 INFO InputInfoTracker: remove old batch metadata: 1638619200000 ms
21/12/04 17:30:10 INFO BlockManager: Removing RDD 154
21/12/04 17:30:10 INFO BlockManagerInfo: Removed input-0-1638619201600 on 10.0.2.15:40275 in memory (size: 1797.6 KiB, free: 364.7 MiB)
21/12/04 17:30:11 INFO MemoryStore: Block input-0-1638619211600 stored as values in memory (estimated size 1718.5 KiB, free 362.9 MiB)
21/12/04 17:30:11 INFO BlockManagerInfo: Added input-0-1638619211600 in memory on 10.0.2.15:40275 (size: 1718.5 KiB, free: 363.0 MiB)
21/12/04 17:30:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:11 WARN BlockManager: Block input-0-1638619211600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:11 INFO BlockGenerator: Pushed block input-0-1638619211600
21/12/04 17:30:15 INFO JobScheduler: Added jobs for time 1638619215000 ms
21/12/04 17:30:15 INFO JobScheduler: Starting job streaming job 1638619215000 ms.0 from job set of time 1638619215000 ms
21/12/04 17:30:15 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:15 INFO DAGScheduler: Got job 65 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:15 INFO DAGScheduler: Final stage: ResultStage 64 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:15 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:15 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:15 INFO DAGScheduler: Submitting ResultStage 64 (BlockRDD[170] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:15 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:15 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:15 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (BlockRDD[170] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:15 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
21/12/04 17:30:15 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 64) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:15 INFO Executor: Running task 0.0 in stage 64.0 (TID 64)
21/12/04 17:30:15 INFO BlockManager: Found block input-0-1638619211600 locally
21/12/04 17:30:15 INFO MemoryStore: Block taskresult_64 stored as bytes in memory (estimated size 1727.7 KiB, free 361.2 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Added taskresult_64 in memory on 10.0.2.15:40275 (size: 1727.7 KiB, free: 361.3 MiB)
21/12/04 17:30:15 INFO Executor: Finished task 0.0 in stage 64.0 (TID 64). 1769194 bytes result sent via BlockManager)
21/12/04 17:30:15 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 64) in 115 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:15 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/12/04 17:30:15 INFO DAGScheduler: ResultStage 64 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.138 s
21/12/04 17:30:15 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/12/04 17:30:15 INFO DAGScheduler: Job 65 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.145922 s
21/12/04 17:30:15 INFO BlockManagerInfo: Removed taskresult_64 on 10.0.2.15:40275 in memory (size: 1727.7 KiB, free: 363.0 MiB)
21/12/04 17:30:15 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:15 INFO DAGScheduler: Got job 66 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:15 INFO DAGScheduler: Final stage: ResultStage 65 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:15 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:15 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:15 INFO DAGScheduler: Submitting ResultStage 65 (BlockRDD[170] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:15 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:15 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:15 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (BlockRDD[170] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:15 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
21/12/04 17:30:15 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 65) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:15 INFO Executor: Running task 0.0 in stage 65.0 (TID 65)
21/12/04 17:30:15 INFO BlockManager: Found block input-0-1638619211600 locally
21/12/04 17:30:15 INFO MemoryStore: Block taskresult_65 stored as bytes in memory (estimated size 1727.7 KiB, free 361.2 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Added taskresult_65 in memory on 10.0.2.15:40275 (size: 1727.7 KiB, free: 361.3 MiB)
21/12/04 17:30:15 INFO Executor: Finished task 0.0 in stage 65.0 (TID 65). 1769194 bytes result sent via BlockManager)
21/12/04 17:30:15 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.3 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.3 MiB)
21/12/04 17:30:15 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 65) in 121 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:15 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/12/04 17:30:15 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 361.3 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Removed taskresult_65 on 10.0.2.15:40275 in memory (size: 1727.7 KiB, free: 363.0 MiB)
21/12/04 17:30:15 INFO DAGScheduler: ResultStage 65 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.136 s
21/12/04 17:30:15 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
21/12/04 17:30:15 INFO DAGScheduler: Job 66 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.142718 s
21/12/04 17:30:15 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:15 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:15 INFO DAGScheduler: Got job 67 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:15 INFO DAGScheduler: Final stage: ResultStage 66 (showString at <unknown>:0)
21/12/04 17:30:15 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:15 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:15 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[177] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:15 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:30:15 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.9 MiB)
21/12/04 17:30:15 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:15 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[177] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:15 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
21/12/04 17:30:15 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 66) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 490613 bytes) taskResourceAssignments Map()
21/12/04 17:30:15 INFO Executor: Running task 0.0 in stage 66.0 (TID 66)
21/12/04 17:30:15 INFO Executor: Finished task 0.0 in stage 66.0 (TID 66). 2393 bytes result sent to driver
21/12/04 17:30:15 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 66) in 18 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:15 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/12/04 17:30:15 INFO DAGScheduler: ResultStage 66 (showString at <unknown>:0) finished in 0.030 s
21/12/04 17:30:15 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/12/04 17:30:15 INFO DAGScheduler: Job 67 finished: showString at <unknown>:0, took 0.044574 s
21/12/04 17:30:15 INFO JobScheduler: Finished job streaming job 1638619215000 ms.0 from job set of time 1638619215000 ms
21/12/04 17:30:15 INFO JobScheduler: Total delay: 0.620 s for time 1638619215000 ms (execution: 0.610 s)
21/12/04 17:30:15 INFO BlockRDD: Removing RDD 162 from persistence list
21/12/04 17:30:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[162] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619215000 ms
21/12/04 17:30:15 INFO ReceivedBlockTracker: Deleting batches: 1638619205000 ms
21/12/04 17:30:15 INFO InputInfoTracker: remove old batch metadata: 1638619205000 ms
21/12/04 17:30:15 INFO BlockManager: Removing RDD 162
21/12/04 17:30:15 INFO BlockManagerInfo: Removed input-0-1638619206600 on 10.0.2.15:40275 in memory (size: 1601.2 KiB, free: 364.6 MiB)
21/12/04 17:30:16 INFO MemoryStore: Block input-0-1638619216600 stored as values in memory (estimated size 1654.2 KiB, free 362.9 MiB)
21/12/04 17:30:16 INFO BlockManagerInfo: Added input-0-1638619216600 in memory on 10.0.2.15:40275 (size: 1654.2 KiB, free: 363.0 MiB)
21/12/04 17:30:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:16 WARN BlockManager: Block input-0-1638619216600 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:16 INFO BlockGenerator: Pushed block input-0-1638619216600
21/12/04 17:30:20 INFO JobScheduler: Added jobs for time 1638619220000 ms
21/12/04 17:30:20 INFO JobScheduler: Starting job streaming job 1638619220000 ms.0 from job set of time 1638619220000 ms
21/12/04 17:30:20 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:20 INFO DAGScheduler: Got job 68 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:20 INFO DAGScheduler: Final stage: ResultStage 67 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:20 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:20 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:20 INFO DAGScheduler: Submitting ResultStage 67 (BlockRDD[178] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:20 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:20 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:20 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:20 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (BlockRDD[178] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:20 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
21/12/04 17:30:20 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 67) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:20 INFO Executor: Running task 0.0 in stage 67.0 (TID 67)
21/12/04 17:30:20 INFO BlockManager: Found block input-0-1638619216600 locally
21/12/04 17:30:20 INFO MemoryStore: Block taskresult_67 stored as bytes in memory (estimated size 1663.1 KiB, free 361.3 MiB)
21/12/04 17:30:20 INFO BlockManagerInfo: Added taskresult_67 in memory on 10.0.2.15:40275 (size: 1663.1 KiB, free: 361.3 MiB)
21/12/04 17:30:20 INFO Executor: Finished task 0.0 in stage 67.0 (TID 67). 1703020 bytes result sent via BlockManager)
21/12/04 17:30:20 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 67) in 49 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:20 INFO BlockManagerInfo: Removed taskresult_67 on 10.0.2.15:40275 in memory (size: 1663.1 KiB, free: 363.0 MiB)
21/12/04 17:30:20 INFO DAGScheduler: ResultStage 67 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.056 s
21/12/04 17:30:20 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:20 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
21/12/04 17:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
21/12/04 17:30:20 INFO DAGScheduler: Job 68 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.061418 s
21/12/04 17:30:20 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:20 INFO DAGScheduler: Got job 69 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:20 INFO DAGScheduler: Final stage: ResultStage 68 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:20 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:20 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:20 INFO DAGScheduler: Submitting ResultStage 68 (BlockRDD[178] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:20 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:20 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:20 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:20 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (BlockRDD[178] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:20 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
21/12/04 17:30:20 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 68) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:20 INFO Executor: Running task 0.0 in stage 68.0 (TID 68)
21/12/04 17:30:20 INFO BlockManager: Found block input-0-1638619216600 locally
21/12/04 17:30:20 INFO MemoryStore: Block taskresult_68 stored as bytes in memory (estimated size 1663.1 KiB, free 361.2 MiB)
21/12/04 17:30:20 INFO BlockManagerInfo: Added taskresult_68 in memory on 10.0.2.15:40275 (size: 1663.1 KiB, free: 361.3 MiB)
21/12/04 17:30:20 INFO Executor: Finished task 0.0 in stage 68.0 (TID 68). 1703020 bytes result sent via BlockManager)
21/12/04 17:30:20 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 68) in 59 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:20 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
21/12/04 17:30:20 INFO BlockManagerInfo: Removed taskresult_68 on 10.0.2.15:40275 in memory (size: 1663.1 KiB, free: 363.0 MiB)
21/12/04 17:30:20 INFO DAGScheduler: ResultStage 68 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.075 s
21/12/04 17:30:20 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
21/12/04 17:30:20 INFO DAGScheduler: Job 69 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.079319 s
21/12/04 17:30:20 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:20 INFO DAGScheduler: Got job 70 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:20 INFO DAGScheduler: Final stage: ResultStage 69 (showString at <unknown>:0)
21/12/04 17:30:20 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:20 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:20 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[185] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:20 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:30:20 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.9 MiB)
21/12/04 17:30:20 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:20 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[185] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:20 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
21/12/04 17:30:20 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 69) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 475362 bytes) taskResourceAssignments Map()
21/12/04 17:30:20 INFO Executor: Running task 0.0 in stage 69.0 (TID 69)
21/12/04 17:30:20 INFO Executor: Finished task 0.0 in stage 69.0 (TID 69). 2210 bytes result sent to driver
21/12/04 17:30:20 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 69) in 24 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:20 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
21/12/04 17:30:20 INFO DAGScheduler: ResultStage 69 (showString at <unknown>:0) finished in 0.041 s
21/12/04 17:30:20 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
21/12/04 17:30:20 INFO DAGScheduler: Job 70 finished: showString at <unknown>:0, took 0.054498 s
21/12/04 17:30:20 INFO JobScheduler: Finished job streaming job 1638619220000 ms.0 from job set of time 1638619220000 ms
21/12/04 17:30:20 INFO JobScheduler: Total delay: 0.398 s for time 1638619220000 ms (execution: 0.389 s)
21/12/04 17:30:20 INFO BlockRDD: Removing RDD 170 from persistence list
21/12/04 17:30:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[170] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619220000 ms
21/12/04 17:30:20 INFO ReceivedBlockTracker: Deleting batches: 1638619210000 ms
21/12/04 17:30:20 INFO InputInfoTracker: remove old batch metadata: 1638619210000 ms
21/12/04 17:30:20 INFO BlockManager: Removing RDD 170
21/12/04 17:30:20 INFO BlockManagerInfo: Removed input-0-1638619211600 on 10.0.2.15:40275 in memory (size: 1718.5 KiB, free: 364.6 MiB)
21/12/04 17:30:22 INFO MemoryStore: Block input-0-1638619221800 stored as values in memory (estimated size 1598.3 KiB, free 363.0 MiB)
21/12/04 17:30:22 INFO BlockManagerInfo: Added input-0-1638619221800 in memory on 10.0.2.15:40275 (size: 1598.3 KiB, free: 363.1 MiB)
21/12/04 17:30:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:22 WARN BlockManager: Block input-0-1638619221800 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:22 INFO BlockGenerator: Pushed block input-0-1638619221800
21/12/04 17:30:25 INFO JobScheduler: Added jobs for time 1638619225000 ms
21/12/04 17:30:25 INFO JobScheduler: Starting job streaming job 1638619225000 ms.0 from job set of time 1638619225000 ms
21/12/04 17:30:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:25 INFO DAGScheduler: Got job 71 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:25 INFO DAGScheduler: Final stage: ResultStage 70 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:25 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:25 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:25 INFO DAGScheduler: Submitting ResultStage 70 (BlockRDD[186] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:25 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 1968.0 B, free 363.0 MiB)
21/12/04 17:30:25 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.0 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:30:25 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (BlockRDD[186] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:25 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
21/12/04 17:30:25 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 70) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:25 INFO Executor: Running task 0.0 in stage 70.0 (TID 70)
21/12/04 17:30:25 INFO BlockManager: Found block input-0-1638619221800 locally
21/12/04 17:30:25 INFO MemoryStore: Block taskresult_70 stored as bytes in memory (estimated size 1607.0 KiB, free 361.4 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Added taskresult_70 in memory on 10.0.2.15:40275 (size: 1607.0 KiB, free: 361.5 MiB)
21/12/04 17:30:25 INFO Executor: Finished task 0.0 in stage 70.0 (TID 70). 1645520 bytes result sent via BlockManager)
21/12/04 17:30:25 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 70) in 65 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:25 INFO DAGScheduler: ResultStage 70 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.079 s
21/12/04 17:30:25 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:25 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
21/12/04 17:30:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
21/12/04 17:30:25 INFO DAGScheduler: Job 71 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.083981 s
21/12/04 17:30:25 INFO BlockManagerInfo: Removed taskresult_70 on 10.0.2.15:40275 in memory (size: 1607.0 KiB, free: 363.1 MiB)
21/12/04 17:30:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:25 INFO DAGScheduler: Got job 72 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:25 INFO DAGScheduler: Final stage: ResultStage 71 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:25 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:25 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:25 INFO DAGScheduler: Submitting ResultStage 71 (BlockRDD[186] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:25 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 1968.0 B, free 363.0 MiB)
21/12/04 17:30:25 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 1210.0 B, free 363.0 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.1 MiB)
21/12/04 17:30:25 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (BlockRDD[186] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:25 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
21/12/04 17:30:25 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 71) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:25 INFO Executor: Running task 0.0 in stage 71.0 (TID 71)
21/12/04 17:30:25 INFO BlockManager: Found block input-0-1638619221800 locally
21/12/04 17:30:25 INFO MemoryStore: Block taskresult_71 stored as bytes in memory (estimated size 1607.0 KiB, free 361.4 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Added taskresult_71 in memory on 10.0.2.15:40275 (size: 1607.0 KiB, free: 361.5 MiB)
21/12/04 17:30:25 INFO Executor: Finished task 0.0 in stage 71.0 (TID 71). 1645520 bytes result sent via BlockManager)
21/12/04 17:30:25 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.5 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 361.5 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 361.5 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.5 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.5 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.5 MiB)
21/12/04 17:30:25 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 71) in 84 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:25 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
21/12/04 17:30:25 INFO DAGScheduler: ResultStage 71 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.106 s
21/12/04 17:30:25 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
21/12/04 17:30:25 INFO BlockManagerInfo: Removed taskresult_71 on 10.0.2.15:40275 in memory (size: 1607.0 KiB, free: 363.1 MiB)
21/12/04 17:30:25 INFO DAGScheduler: Job 72 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.110982 s
21/12/04 17:30:25 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:25 INFO DAGScheduler: Got job 73 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:25 INFO DAGScheduler: Final stage: ResultStage 72 (showString at <unknown>:0)
21/12/04 17:30:25 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:25 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:25 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[193] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:25 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 10.9 KiB, free 363.0 MiB)
21/12/04 17:30:25 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 363.0 MiB)
21/12/04 17:30:25 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.1 MiB)
21/12/04 17:30:25 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[193] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:25 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
21/12/04 17:30:25 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 72) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 368228 bytes) taskResourceAssignments Map()
21/12/04 17:30:25 INFO Executor: Running task 0.0 in stage 72.0 (TID 72)
21/12/04 17:30:25 INFO Executor: Finished task 0.0 in stage 72.0 (TID 72). 2243 bytes result sent to driver
21/12/04 17:30:25 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 72) in 65 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:25 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
21/12/04 17:30:25 INFO DAGScheduler: ResultStage 72 (showString at <unknown>:0) finished in 0.083 s
21/12/04 17:30:25 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
21/12/04 17:30:25 INFO DAGScheduler: Job 73 finished: showString at <unknown>:0, took 0.091222 s
21/12/04 17:30:25 INFO JobScheduler: Finished job streaming job 1638619225000 ms.0 from job set of time 1638619225000 ms
21/12/04 17:30:25 INFO JobScheduler: Total delay: 0.443 s for time 1638619225000 ms (execution: 0.439 s)
21/12/04 17:30:25 INFO BlockRDD: Removing RDD 178 from persistence list
21/12/04 17:30:25 INFO BlockManager: Removing RDD 178
21/12/04 17:30:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[178] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619225000 ms
21/12/04 17:30:25 INFO ReceivedBlockTracker: Deleting batches: 1638619215000 ms
21/12/04 17:30:25 INFO InputInfoTracker: remove old batch metadata: 1638619215000 ms
21/12/04 17:30:25 INFO BlockManagerInfo: Removed input-0-1638619216600 on 10.0.2.15:40275 in memory (size: 1654.2 KiB, free: 364.7 MiB)
21/12/04 17:30:27 INFO MemoryStore: Block input-0-1638619226800 stored as values in memory (estimated size 1714.0 KiB, free 362.9 MiB)
21/12/04 17:30:27 INFO BlockManagerInfo: Added input-0-1638619226800 in memory on 10.0.2.15:40275 (size: 1714.0 KiB, free: 363.0 MiB)
21/12/04 17:30:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:27 WARN BlockManager: Block input-0-1638619226800 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:27 INFO BlockGenerator: Pushed block input-0-1638619226800
21/12/04 17:30:30 INFO JobScheduler: Added jobs for time 1638619230000 ms
21/12/04 17:30:30 INFO JobScheduler: Starting job streaming job 1638619230000 ms.0 from job set of time 1638619230000 ms
21/12/04 17:30:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:30 INFO DAGScheduler: Got job 74 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:30 INFO DAGScheduler: Final stage: ResultStage 73 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:30 INFO DAGScheduler: Submitting ResultStage 73 (BlockRDD[194] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:30 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:30 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:30 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:30 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (BlockRDD[194] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:30 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
21/12/04 17:30:30 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 73) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:30 INFO Executor: Running task 0.0 in stage 73.0 (TID 73)
21/12/04 17:30:30 INFO BlockManager: Found block input-0-1638619226800 locally
21/12/04 17:30:30 INFO MemoryStore: Block taskresult_73 stored as bytes in memory (estimated size 1723.3 KiB, free 361.3 MiB)
21/12/04 17:30:30 INFO BlockManagerInfo: Added taskresult_73 in memory on 10.0.2.15:40275 (size: 1723.3 KiB, free: 361.3 MiB)
21/12/04 17:30:30 INFO Executor: Finished task 0.0 in stage 73.0 (TID 73). 1764632 bytes result sent via BlockManager)
21/12/04 17:30:30 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 73) in 45 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:30 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
21/12/04 17:30:30 INFO DAGScheduler: ResultStage 73 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.053 s
21/12/04 17:30:30 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
21/12/04 17:30:30 INFO DAGScheduler: Job 74 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.057463 s
21/12/04 17:30:30 INFO BlockManagerInfo: Removed taskresult_73 on 10.0.2.15:40275 in memory (size: 1723.3 KiB, free: 363.0 MiB)
21/12/04 17:30:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:30 INFO DAGScheduler: Got job 75 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:30 INFO DAGScheduler: Final stage: ResultStage 74 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:30 INFO DAGScheduler: Submitting ResultStage 74 (BlockRDD[194] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:30 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:30 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:30 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:30 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (BlockRDD[194] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:30 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
21/12/04 17:30:30 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 74) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:30 INFO Executor: Running task 0.0 in stage 74.0 (TID 74)
21/12/04 17:30:30 INFO BlockManager: Found block input-0-1638619226800 locally
21/12/04 17:30:30 INFO MemoryStore: Block taskresult_74 stored as bytes in memory (estimated size 1723.3 KiB, free 361.2 MiB)
21/12/04 17:30:30 INFO BlockManagerInfo: Added taskresult_74 in memory on 10.0.2.15:40275 (size: 1723.3 KiB, free: 361.3 MiB)
21/12/04 17:30:30 INFO Executor: Finished task 0.0 in stage 74.0 (TID 74). 1764632 bytes result sent via BlockManager)
21/12/04 17:30:30 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 74) in 71 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:30 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
21/12/04 17:30:30 INFO DAGScheduler: ResultStage 74 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.078 s
21/12/04 17:30:30 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
21/12/04 17:30:30 INFO DAGScheduler: Job 75 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.081745 s
21/12/04 17:30:30 INFO BlockManagerInfo: Removed taskresult_74 on 10.0.2.15:40275 in memory (size: 1723.3 KiB, free: 363.0 MiB)
21/12/04 17:30:30 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:30 INFO DAGScheduler: Got job 76 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:30 INFO DAGScheduler: Final stage: ResultStage 75 (showString at <unknown>:0)
21/12/04 17:30:30 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:30 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:30 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[201] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:30 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:30:30 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.9 MiB)
21/12/04 17:30:30 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:30 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[201] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:30 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
21/12/04 17:30:30 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 75) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 385702 bytes) taskResourceAssignments Map()
21/12/04 17:30:30 INFO Executor: Running task 0.0 in stage 75.0 (TID 75)
21/12/04 17:30:30 INFO Executor: Finished task 0.0 in stage 75.0 (TID 75). 2167 bytes result sent to driver
21/12/04 17:30:30 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 75) in 74 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:30 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
21/12/04 17:30:30 INFO DAGScheduler: ResultStage 75 (showString at <unknown>:0) finished in 0.091 s
21/12/04 17:30:30 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
21/12/04 17:30:30 INFO DAGScheduler: Job 76 finished: showString at <unknown>:0, took 0.109756 s
21/12/04 17:30:30 INFO JobScheduler: Finished job streaming job 1638619230000 ms.0 from job set of time 1638619230000 ms
21/12/04 17:30:30 INFO JobScheduler: Total delay: 0.526 s for time 1638619230000 ms (execution: 0.521 s)
21/12/04 17:30:30 INFO BlockRDD: Removing RDD 186 from persistence list
21/12/04 17:30:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[186] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619230000 ms
21/12/04 17:30:30 INFO ReceivedBlockTracker: Deleting batches: 1638619220000 ms
21/12/04 17:30:30 INFO InputInfoTracker: remove old batch metadata: 1638619220000 ms
21/12/04 17:30:30 INFO BlockManager: Removing RDD 186
21/12/04 17:30:30 INFO BlockManagerInfo: Removed input-0-1638619221800 on 10.0.2.15:40275 in memory (size: 1598.3 KiB, free: 364.6 MiB)
21/12/04 17:30:32 INFO MemoryStore: Block input-0-1638619231800 stored as values in memory (estimated size 1626.3 KiB, free 362.9 MiB)
21/12/04 17:30:32 INFO BlockManagerInfo: Added input-0-1638619231800 in memory on 10.0.2.15:40275 (size: 1626.3 KiB, free: 363.0 MiB)
21/12/04 17:30:32 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:32 WARN BlockManager: Block input-0-1638619231800 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:32 INFO BlockGenerator: Pushed block input-0-1638619231800
21/12/04 17:30:35 INFO JobScheduler: Added jobs for time 1638619235000 ms
21/12/04 17:30:35 INFO JobScheduler: Starting job streaming job 1638619235000 ms.0 from job set of time 1638619235000 ms
21/12/04 17:30:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:35 INFO DAGScheduler: Got job 77 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:35 INFO DAGScheduler: Final stage: ResultStage 76 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:35 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:35 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:35 INFO DAGScheduler: Submitting ResultStage 76 (BlockRDD[202] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:35 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:35 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:35 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (BlockRDD[202] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:35 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
21/12/04 17:30:35 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 76) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:35 INFO Executor: Running task 0.0 in stage 76.0 (TID 76)
21/12/04 17:30:35 INFO BlockManager: Found block input-0-1638619231800 locally
21/12/04 17:30:35 INFO MemoryStore: Block taskresult_76 stored as bytes in memory (estimated size 1635.0 KiB, free 361.3 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Added taskresult_76 in memory on 10.0.2.15:40275 (size: 1635.0 KiB, free: 361.4 MiB)
21/12/04 17:30:35 INFO Executor: Finished task 0.0 in stage 76.0 (TID 76). 1674276 bytes result sent via BlockManager)
21/12/04 17:30:35 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 76) in 77 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:35 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
21/12/04 17:30:35 INFO DAGScheduler: ResultStage 76 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.105 s
21/12/04 17:30:35 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
21/12/04 17:30:35 INFO DAGScheduler: Job 77 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.125756 s
21/12/04 17:30:35 INFO BlockManagerInfo: Removed taskresult_76 on 10.0.2.15:40275 in memory (size: 1635.0 KiB, free: 363.0 MiB)
21/12/04 17:30:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:35 INFO DAGScheduler: Got job 78 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:35 INFO DAGScheduler: Final stage: ResultStage 77 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:35 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:35 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:35 INFO DAGScheduler: Submitting ResultStage 77 (BlockRDD[202] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:35 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:35 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:35 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (BlockRDD[202] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:35 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0
21/12/04 17:30:35 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 77) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:35 INFO Executor: Running task 0.0 in stage 77.0 (TID 77)
21/12/04 17:30:35 INFO BlockManager: Found block input-0-1638619231800 locally
21/12/04 17:30:35 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:35 INFO MemoryStore: Block taskresult_77 stored as bytes in memory (estimated size 1635.1 KiB, free 361.3 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Added taskresult_77 in memory on 10.0.2.15:40275 (size: 1635.1 KiB, free: 361.4 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 361.4 MiB)
21/12/04 17:30:35 INFO Executor: Finished task 0.0 in stage 77.0 (TID 77). 1674362 bytes result sent via BlockManager)
21/12/04 17:30:35 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 77) in 113 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:35 INFO DAGScheduler: ResultStage 77 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.128 s
21/12/04 17:30:35 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:35 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
21/12/04 17:30:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
21/12/04 17:30:35 INFO DAGScheduler: Job 78 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.133887 s
21/12/04 17:30:35 INFO BlockManagerInfo: Removed taskresult_77 on 10.0.2.15:40275 in memory (size: 1635.1 KiB, free: 363.0 MiB)
21/12/04 17:30:35 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:35 INFO DAGScheduler: Got job 79 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:35 INFO DAGScheduler: Final stage: ResultStage 78 (showString at <unknown>:0)
21/12/04 17:30:35 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:35 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:35 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[209] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:35 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:30:35 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.9 MiB)
21/12/04 17:30:35 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:35 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[209] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:35 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
21/12/04 17:30:35 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 78) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 433564 bytes) taskResourceAssignments Map()
21/12/04 17:30:35 INFO Executor: Running task 0.0 in stage 78.0 (TID 78)
21/12/04 17:30:35 INFO Executor: Finished task 0.0 in stage 78.0 (TID 78). 2281 bytes result sent to driver
21/12/04 17:30:35 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 78) in 23 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:35 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
21/12/04 17:30:35 INFO DAGScheduler: ResultStage 78 (showString at <unknown>:0) finished in 0.053 s
21/12/04 17:30:35 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
21/12/04 17:30:35 INFO DAGScheduler: Job 79 finished: showString at <unknown>:0, took 0.080027 s
21/12/04 17:30:35 INFO JobScheduler: Finished job streaming job 1638619235000 ms.0 from job set of time 1638619235000 ms
21/12/04 17:30:35 INFO JobScheduler: Total delay: 0.611 s for time 1638619235000 ms (execution: 0.606 s)
21/12/04 17:30:35 INFO BlockRDD: Removing RDD 194 from persistence list
21/12/04 17:30:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[194] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619235000 ms
21/12/04 17:30:35 INFO ReceivedBlockTracker: Deleting batches: 1638619225000 ms
21/12/04 17:30:35 INFO InputInfoTracker: remove old batch metadata: 1638619225000 ms
21/12/04 17:30:35 INFO BlockManager: Removing RDD 194
21/12/04 17:30:35 INFO BlockManagerInfo: Removed input-0-1638619226800 on 10.0.2.15:40275 in memory (size: 1714.0 KiB, free: 364.7 MiB)
21/12/04 17:30:37 INFO MemoryStore: Block input-0-1638619236800 stored as values in memory (estimated size 1850.6 KiB, free 362.8 MiB)
21/12/04 17:30:37 INFO BlockManagerInfo: Added input-0-1638619236800 in memory on 10.0.2.15:40275 (size: 1850.6 KiB, free: 362.9 MiB)
21/12/04 17:30:37 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:37 WARN BlockManager: Block input-0-1638619236800 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:37 INFO BlockGenerator: Pushed block input-0-1638619236800
21/12/04 17:30:40 INFO JobScheduler: Added jobs for time 1638619240000 ms
21/12/04 17:30:40 INFO JobScheduler: Starting job streaming job 1638619240000 ms.0 from job set of time 1638619240000 ms
21/12/04 17:30:40 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:40 INFO DAGScheduler: Got job 80 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:40 INFO DAGScheduler: Final stage: ResultStage 79 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:40 INFO DAGScheduler: Submitting ResultStage 79 (BlockRDD[210] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:40 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:30:40 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:30:40 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:30:40 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (BlockRDD[210] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:40 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
21/12/04 17:30:40 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 79) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:40 INFO Executor: Running task 0.0 in stage 79.0 (TID 79)
21/12/04 17:30:40 INFO BlockManager: Found block input-0-1638619236800 locally
21/12/04 17:30:40 INFO MemoryStore: Block taskresult_79 stored as bytes in memory (estimated size 1860.5 KiB, free 361.0 MiB)
21/12/04 17:30:40 INFO BlockManagerInfo: Added taskresult_79 in memory on 10.0.2.15:40275 (size: 1860.5 KiB, free: 361.1 MiB)
21/12/04 17:30:40 INFO Executor: Finished task 0.0 in stage 79.0 (TID 79). 1905185 bytes result sent via BlockManager)
21/12/04 17:30:40 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 79) in 72 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:40 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
21/12/04 17:30:40 INFO BlockManagerInfo: Removed taskresult_79 on 10.0.2.15:40275 in memory (size: 1860.5 KiB, free: 362.9 MiB)
21/12/04 17:30:40 INFO DAGScheduler: ResultStage 79 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.087 s
21/12/04 17:30:40 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
21/12/04 17:30:40 INFO DAGScheduler: Job 80 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.101120 s
21/12/04 17:30:40 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:40 INFO DAGScheduler: Got job 81 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:40 INFO DAGScheduler: Final stage: ResultStage 80 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:40 INFO DAGScheduler: Submitting ResultStage 80 (BlockRDD[210] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:40 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 1968.0 B, free 362.8 MiB)
21/12/04 17:30:40 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.8 MiB)
21/12/04 17:30:40 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.9 MiB)
21/12/04 17:30:40 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (BlockRDD[210] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:40 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
21/12/04 17:30:40 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 80) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:40 INFO Executor: Running task 0.0 in stage 80.0 (TID 80)
21/12/04 17:30:40 INFO BlockManager: Found block input-0-1638619236800 locally
21/12/04 17:30:40 INFO MemoryStore: Block taskresult_80 stored as bytes in memory (estimated size 1860.5 KiB, free 361.0 MiB)
21/12/04 17:30:40 INFO BlockManagerInfo: Added taskresult_80 in memory on 10.0.2.15:40275 (size: 1860.5 KiB, free: 361.1 MiB)
21/12/04 17:30:40 INFO Executor: Finished task 0.0 in stage 80.0 (TID 80). 1905185 bytes result sent via BlockManager)
21/12/04 17:30:40 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 80) in 71 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:40 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
21/12/04 17:30:40 INFO BlockManagerInfo: Removed taskresult_80 on 10.0.2.15:40275 in memory (size: 1860.5 KiB, free: 362.9 MiB)
21/12/04 17:30:40 INFO DAGScheduler: ResultStage 80 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.087 s
21/12/04 17:30:40 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished
21/12/04 17:30:40 INFO DAGScheduler: Job 81 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.099394 s
21/12/04 17:30:40 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:40 INFO DAGScheduler: Got job 82 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:40 INFO DAGScheduler: Final stage: ResultStage 81 (showString at <unknown>:0)
21/12/04 17:30:40 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:40 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:40 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[217] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:40 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.9 KiB, free 362.8 MiB)
21/12/04 17:30:40 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.8 MiB)
21/12/04 17:30:40 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.9 MiB)
21/12/04 17:30:40 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[217] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:40 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
21/12/04 17:30:40 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 81) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 353802 bytes) taskResourceAssignments Map()
21/12/04 17:30:40 INFO Executor: Running task 0.0 in stage 81.0 (TID 81)
21/12/04 17:30:40 INFO Executor: Finished task 0.0 in stage 81.0 (TID 81). 2449 bytes result sent to driver
21/12/04 17:30:40 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 81) in 98 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:40 INFO DAGScheduler: ResultStage 81 (showString at <unknown>:0) finished in 0.107 s
21/12/04 17:30:40 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:40 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
21/12/04 17:30:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
21/12/04 17:30:40 INFO DAGScheduler: Job 82 finished: showString at <unknown>:0, took 0.112215 s
21/12/04 17:30:40 INFO JobScheduler: Finished job streaming job 1638619240000 ms.0 from job set of time 1638619240000 ms
21/12/04 17:30:40 INFO JobScheduler: Total delay: 0.642 s for time 1638619240000 ms (execution: 0.637 s)
21/12/04 17:30:40 INFO BlockRDD: Removing RDD 202 from persistence list
21/12/04 17:30:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[202] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619240000 ms
21/12/04 17:30:40 INFO ReceivedBlockTracker: Deleting batches: 1638619230000 ms
21/12/04 17:30:40 INFO InputInfoTracker: remove old batch metadata: 1638619230000 ms
21/12/04 17:30:40 INFO BlockManager: Removing RDD 202
21/12/04 17:30:40 INFO BlockManagerInfo: Removed input-0-1638619231800 on 10.0.2.15:40275 in memory (size: 1626.3 KiB, free: 364.5 MiB)
21/12/04 17:30:42 INFO MemoryStore: Block input-0-1638619241800 stored as values in memory (estimated size 1909.9 KiB, free 362.5 MiB)
21/12/04 17:30:42 INFO BlockManagerInfo: Added input-0-1638619241800 in memory on 10.0.2.15:40275 (size: 1909.9 KiB, free: 362.6 MiB)
21/12/04 17:30:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:42 WARN BlockManager: Block input-0-1638619241800 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:42 INFO BlockGenerator: Pushed block input-0-1638619241800
21/12/04 17:30:45 INFO JobScheduler: Added jobs for time 1638619245000 ms
21/12/04 17:30:45 INFO JobScheduler: Starting job streaming job 1638619245000 ms.0 from job set of time 1638619245000 ms
21/12/04 17:30:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:45 INFO DAGScheduler: Got job 83 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:45 INFO DAGScheduler: Final stage: ResultStage 82 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:45 INFO DAGScheduler: Submitting ResultStage 82 (BlockRDD[218] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:45 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 1968.0 B, free 362.5 MiB)
21/12/04 17:30:45 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.5 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.6 MiB)
21/12/04 17:30:45 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (BlockRDD[218] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:45 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
21/12/04 17:30:45 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 82) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:45 INFO Executor: Running task 0.0 in stage 82.0 (TID 82)
21/12/04 17:30:45 INFO BlockManager: Found block input-0-1638619241800 locally
21/12/04 17:30:45 INFO MemoryStore: Block taskresult_82 stored as bytes in memory (estimated size 1920.0 KiB, free 360.6 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Added taskresult_82 in memory on 10.0.2.15:40275 (size: 1920.0 KiB, free: 360.7 MiB)
21/12/04 17:30:45 INFO Executor: Finished task 0.0 in stage 82.0 (TID 82). 1966084 bytes result sent via BlockManager)
21/12/04 17:30:45 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 360.7 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 360.7 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 360.7 MiB)
21/12/04 17:30:45 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 82) in 133 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:45 INFO DAGScheduler: ResultStage 82 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.139 s
21/12/04 17:30:45 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:45 INFO BlockManagerInfo: Removed taskresult_82 on 10.0.2.15:40275 in memory (size: 1920.0 KiB, free: 362.6 MiB)
21/12/04 17:30:45 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
21/12/04 17:30:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
21/12/04 17:30:45 INFO DAGScheduler: Job 83 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.145599 s
21/12/04 17:30:45 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.6 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 362.6 MiB)
21/12/04 17:30:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:45 INFO DAGScheduler: Got job 84 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:45 INFO DAGScheduler: Final stage: ResultStage 83 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:45 INFO DAGScheduler: Submitting ResultStage 83 (BlockRDD[218] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:45 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 1968.0 B, free 362.5 MiB)
21/12/04 17:30:45 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.5 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.6 MiB)
21/12/04 17:30:45 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (BlockRDD[218] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:45 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0
21/12/04 17:30:45 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 83) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:45 INFO Executor: Running task 0.0 in stage 83.0 (TID 83)
21/12/04 17:30:45 INFO BlockManager: Found block input-0-1638619241800 locally
21/12/04 17:30:45 INFO MemoryStore: Block taskresult_83 stored as bytes in memory (estimated size 1920.0 KiB, free 360.6 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Added taskresult_83 in memory on 10.0.2.15:40275 (size: 1920.0 KiB, free: 360.7 MiB)
21/12/04 17:30:45 INFO Executor: Finished task 0.0 in stage 83.0 (TID 83). 1966127 bytes result sent via BlockManager)
21/12/04 17:30:45 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 83) in 188 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:45 INFO DAGScheduler: ResultStage 83 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.217 s
21/12/04 17:30:45 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:45 INFO BlockManagerInfo: Removed taskresult_83 on 10.0.2.15:40275 in memory (size: 1920.0 KiB, free: 362.6 MiB)
21/12/04 17:30:45 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
21/12/04 17:30:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
21/12/04 17:30:45 INFO DAGScheduler: Job 84 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.228495 s
21/12/04 17:30:45 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:45 INFO DAGScheduler: Got job 85 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:45 INFO DAGScheduler: Final stage: ResultStage 84 (showString at <unknown>:0)
21/12/04 17:30:45 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:45 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:45 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[225] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:45 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 10.9 KiB, free 362.5 MiB)
21/12/04 17:30:45 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.5 MiB)
21/12/04 17:30:45 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.6 MiB)
21/12/04 17:30:45 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[225] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:45 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
21/12/04 17:30:45 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 84) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 338111 bytes) taskResourceAssignments Map()
21/12/04 17:30:45 INFO Executor: Running task 0.0 in stage 84.0 (TID 84)
21/12/04 17:30:45 INFO Executor: Finished task 0.0 in stage 84.0 (TID 84). 2300 bytes result sent to driver
21/12/04 17:30:45 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 84) in 81 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:45 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
21/12/04 17:30:45 INFO DAGScheduler: ResultStage 84 (showString at <unknown>:0) finished in 0.112 s
21/12/04 17:30:45 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
21/12/04 17:30:45 INFO DAGScheduler: Job 85 finished: showString at <unknown>:0, took 0.122147 s
21/12/04 17:30:45 INFO JobScheduler: Finished job streaming job 1638619245000 ms.0 from job set of time 1638619245000 ms
21/12/04 17:30:45 INFO JobScheduler: Total delay: 0.959 s for time 1638619245000 ms (execution: 0.950 s)
21/12/04 17:30:45 INFO BlockRDD: Removing RDD 210 from persistence list
21/12/04 17:30:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[210] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619245000 ms
21/12/04 17:30:45 INFO ReceivedBlockTracker: Deleting batches: 1638619235000 ms
21/12/04 17:30:45 INFO InputInfoTracker: remove old batch metadata: 1638619235000 ms
21/12/04 17:30:45 INFO BlockManager: Removing RDD 210
21/12/04 17:30:45 INFO BlockManagerInfo: Removed input-0-1638619236800 on 10.0.2.15:40275 in memory (size: 1850.6 KiB, free: 364.4 MiB)
21/12/04 17:30:47 INFO MemoryStore: Block input-0-1638619246800 stored as values in memory (estimated size 1747.5 KiB, free 362.6 MiB)
21/12/04 17:30:47 INFO BlockManagerInfo: Added input-0-1638619246800 in memory on 10.0.2.15:40275 (size: 1747.5 KiB, free: 362.7 MiB)
21/12/04 17:30:47 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:47 WARN BlockManager: Block input-0-1638619246800 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:47 INFO BlockGenerator: Pushed block input-0-1638619246800
21/12/04 17:30:50 INFO JobScheduler: Added jobs for time 1638619250000 ms
21/12/04 17:30:50 INFO JobScheduler: Starting job streaming job 1638619250000 ms.0 from job set of time 1638619250000 ms
21/12/04 17:30:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:50 INFO DAGScheduler: Got job 86 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:50 INFO DAGScheduler: Final stage: ResultStage 85 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:50 INFO DAGScheduler: Submitting ResultStage 85 (BlockRDD[226] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:50 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 1968.0 B, free 362.6 MiB)
21/12/04 17:30:50 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.6 MiB)
21/12/04 17:30:50 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:30:50 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (BlockRDD[226] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:50 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
21/12/04 17:30:50 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 85) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:50 INFO Executor: Running task 0.0 in stage 85.0 (TID 85)
21/12/04 17:30:50 INFO BlockManager: Found block input-0-1638619246800 locally
21/12/04 17:30:50 INFO MemoryStore: Block taskresult_85 stored as bytes in memory (estimated size 1756.9 KiB, free 360.9 MiB)
21/12/04 17:30:50 INFO BlockManagerInfo: Added taskresult_85 in memory on 10.0.2.15:40275 (size: 1756.9 KiB, free: 361.0 MiB)
21/12/04 17:30:50 INFO Executor: Finished task 0.0 in stage 85.0 (TID 85). 1799044 bytes result sent via BlockManager)
21/12/04 17:30:50 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 85) in 48 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:50 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
21/12/04 17:30:50 INFO DAGScheduler: ResultStage 85 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.067 s
21/12/04 17:30:50 INFO BlockManagerInfo: Removed taskresult_85 on 10.0.2.15:40275 in memory (size: 1756.9 KiB, free: 362.7 MiB)
21/12/04 17:30:50 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
21/12/04 17:30:50 INFO DAGScheduler: Job 86 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.076112 s
21/12/04 17:30:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:50 INFO DAGScheduler: Got job 87 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:50 INFO DAGScheduler: Final stage: ResultStage 86 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:50 INFO DAGScheduler: Submitting ResultStage 86 (BlockRDD[226] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:50 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 1968.0 B, free 362.6 MiB)
21/12/04 17:30:50 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.6 MiB)
21/12/04 17:30:50 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 362.7 MiB)
21/12/04 17:30:50 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (BlockRDD[226] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:50 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0
21/12/04 17:30:50 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 86) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:50 INFO Executor: Running task 0.0 in stage 86.0 (TID 86)
21/12/04 17:30:50 INFO BlockManager: Found block input-0-1638619246800 locally
21/12/04 17:30:50 INFO MemoryStore: Block taskresult_86 stored as bytes in memory (estimated size 1756.9 KiB, free 360.9 MiB)
21/12/04 17:30:50 INFO BlockManagerInfo: Added taskresult_86 in memory on 10.0.2.15:40275 (size: 1756.9 KiB, free: 361.0 MiB)
21/12/04 17:30:50 INFO Executor: Finished task 0.0 in stage 86.0 (TID 86). 1799044 bytes result sent via BlockManager)
21/12/04 17:30:50 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 86) in 119 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:50 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
21/12/04 17:30:50 INFO DAGScheduler: ResultStage 86 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.142 s
21/12/04 17:30:50 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
21/12/04 17:30:50 INFO DAGScheduler: Job 87 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.151005 s
21/12/04 17:30:50 INFO BlockManagerInfo: Removed taskresult_86 on 10.0.2.15:40275 in memory (size: 1756.9 KiB, free: 362.7 MiB)
21/12/04 17:30:50 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:50 INFO DAGScheduler: Got job 88 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:50 INFO DAGScheduler: Final stage: ResultStage 87 (showString at <unknown>:0)
21/12/04 17:30:50 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:50 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:50 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[233] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:50 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 10.9 KiB, free 362.6 MiB)
21/12/04 17:30:50 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.6 MiB)
21/12/04 17:30:50 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 362.7 MiB)
21/12/04 17:30:50 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[233] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:50 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
21/12/04 17:30:50 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 87) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 350538 bytes) taskResourceAssignments Map()
21/12/04 17:30:50 INFO Executor: Running task 0.0 in stage 87.0 (TID 87)
21/12/04 17:30:50 INFO Executor: Finished task 0.0 in stage 87.0 (TID 87). 2284 bytes result sent to driver
21/12/04 17:30:50 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 87) in 113 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:50 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
21/12/04 17:30:50 INFO DAGScheduler: ResultStage 87 (showString at <unknown>:0) finished in 0.127 s
21/12/04 17:30:50 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
21/12/04 17:30:50 INFO DAGScheduler: Job 88 finished: showString at <unknown>:0, took 0.139980 s
21/12/04 17:30:50 INFO JobScheduler: Finished job streaming job 1638619250000 ms.0 from job set of time 1638619250000 ms
21/12/04 17:30:50 INFO JobScheduler: Total delay: 0.700 s for time 1638619250000 ms (execution: 0.695 s)
21/12/04 17:30:50 INFO BlockRDD: Removing RDD 218 from persistence list
21/12/04 17:30:50 INFO BlockManager: Removing RDD 218
21/12/04 17:30:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[218] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619250000 ms
21/12/04 17:30:50 INFO ReceivedBlockTracker: Deleting batches: 1638619240000 ms
21/12/04 17:30:50 INFO InputInfoTracker: remove old batch metadata: 1638619240000 ms
21/12/04 17:30:50 INFO BlockManagerInfo: Removed input-0-1638619241800 on 10.0.2.15:40275 in memory (size: 1909.9 KiB, free: 364.5 MiB)
21/12/04 17:30:52 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 364.6 MiB)
21/12/04 17:30:52 INFO MemoryStore: Block input-0-1638619251800 stored as values in memory (estimated size 1592.0 KiB, free 362.9 MiB)
21/12/04 17:30:52 INFO BlockManagerInfo: Added input-0-1638619251800 in memory on 10.0.2.15:40275 (size: 1592.0 KiB, free: 363.0 MiB)
21/12/04 17:30:52 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/04 17:30:52 WARN BlockManager: Block input-0-1638619251800 replicated to only 0 peer(s) instead of 1 peers
21/12/04 17:30:52 INFO BlockGenerator: Pushed block input-0-1638619251800
21/12/04 17:30:52 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:52 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 10.0.2.15:40275 in memory (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:52 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:52 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:52 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 10.0.2.15:40275 in memory (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:55 INFO JobScheduler: Added jobs for time 1638619255000 ms
21/12/04 17:30:55 INFO JobScheduler: Starting job streaming job 1638619255000 ms.0 from job set of time 1638619255000 ms
21/12/04 17:30:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:55 INFO DAGScheduler: Got job 89 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:55 INFO DAGScheduler: Final stage: ResultStage 88 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:55 INFO DAGScheduler: Submitting ResultStage 88 (BlockRDD[234] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:55 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:55 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:55 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:55 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (BlockRDD[234] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:55 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
21/12/04 17:30:55 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 88) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:55 INFO Executor: Running task 0.0 in stage 88.0 (TID 88)
21/12/04 17:30:55 INFO BlockManager: Found block input-0-1638619251800 locally
21/12/04 17:30:55 INFO MemoryStore: Block taskresult_88 stored as bytes in memory (estimated size 1600.6 KiB, free 361.4 MiB)
21/12/04 17:30:55 INFO BlockManagerInfo: Added taskresult_88 in memory on 10.0.2.15:40275 (size: 1600.6 KiB, free: 361.4 MiB)
21/12/04 17:30:55 INFO Executor: Finished task 0.0 in stage 88.0 (TID 88). 1639052 bytes result sent via BlockManager)
21/12/04 17:30:55 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 88) in 72 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:55 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
21/12/04 17:30:55 INFO BlockManagerInfo: Removed taskresult_88 on 10.0.2.15:40275 in memory (size: 1600.6 KiB, free: 363.0 MiB)
21/12/04 17:30:55 INFO DAGScheduler: ResultStage 88 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.089 s
21/12/04 17:30:55 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
21/12/04 17:30:55 INFO DAGScheduler: Job 89 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.091994 s
21/12/04 17:30:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:30:55 INFO DAGScheduler: Got job 90 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/04 17:30:55 INFO DAGScheduler: Final stage: ResultStage 89 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/04 17:30:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:55 INFO DAGScheduler: Submitting ResultStage 89 (BlockRDD[234] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/04 17:30:55 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 1968.0 B, free 362.9 MiB)
21/12/04 17:30:55 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 1210.0 B, free 362.9 MiB)
21/12/04 17:30:55 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.0.2.15:40275 (size: 1210.0 B, free: 363.0 MiB)
21/12/04 17:30:55 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (BlockRDD[234] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:55 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
21/12/04 17:30:55 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 89) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/04 17:30:55 INFO Executor: Running task 0.0 in stage 89.0 (TID 89)
21/12/04 17:30:55 INFO BlockManager: Found block input-0-1638619251800 locally
21/12/04 17:30:55 INFO MemoryStore: Block taskresult_89 stored as bytes in memory (estimated size 1600.6 KiB, free 361.4 MiB)
21/12/04 17:30:55 INFO BlockManagerInfo: Added taskresult_89 in memory on 10.0.2.15:40275 (size: 1600.6 KiB, free: 361.4 MiB)
21/12/04 17:30:55 INFO Executor: Finished task 0.0 in stage 89.0 (TID 89). 1639052 bytes result sent via BlockManager)
21/12/04 17:30:55 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 89) in 123 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:55 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
21/12/04 17:30:55 INFO DAGScheduler: ResultStage 89 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.137 s
21/12/04 17:30:55 INFO DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
21/12/04 17:30:55 INFO DAGScheduler: Job 90 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.142190 s
21/12/04 17:30:55 INFO BlockManagerInfo: Removed taskresult_89 on 10.0.2.15:40275 in memory (size: 1600.6 KiB, free: 363.0 MiB)
21/12/04 17:30:55 INFO SparkContext: Starting job: showString at <unknown>:0
21/12/04 17:30:55 INFO DAGScheduler: Got job 91 (showString at <unknown>:0) with 1 output partitions
21/12/04 17:30:55 INFO DAGScheduler: Final stage: ResultStage 90 (showString at <unknown>:0)
21/12/04 17:30:55 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:30:55 INFO DAGScheduler: Missing parents: List()
21/12/04 17:30:55 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[241] at showString at <unknown>:0), which has no missing parents
21/12/04 17:30:55 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 10.9 KiB, free 362.9 MiB)
21/12/04 17:30:55 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 362.9 MiB)
21/12/04 17:30:55 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.0.2.15:40275 (size: 5.8 KiB, free: 363.0 MiB)
21/12/04 17:30:55 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1388
21/12/04 17:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[241] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/12/04 17:30:55 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
21/12/04 17:30:55 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 90) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 354309 bytes) taskResourceAssignments Map()
21/12/04 17:30:55 INFO Executor: Running task 0.0 in stage 90.0 (TID 90)
21/12/04 17:30:55 INFO Executor: Finished task 0.0 in stage 90.0 (TID 90). 2202 bytes result sent to driver
21/12/04 17:30:55 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 90) in 111 ms on 10.0.2.15 (executor driver) (1/1)
21/12/04 17:30:55 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
21/12/04 17:30:55 INFO DAGScheduler: ResultStage 90 (showString at <unknown>:0) finished in 0.135 s
21/12/04 17:30:55 INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/04 17:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
21/12/04 17:30:55 INFO DAGScheduler: Job 91 finished: showString at <unknown>:0, took 0.151411 s
21/12/04 17:30:55 INFO JobScheduler: Finished job streaming job 1638619255000 ms.0 from job set of time 1638619255000 ms
21/12/04 17:30:55 INFO JobScheduler: Total delay: 0.639 s for time 1638619255000 ms (execution: 0.631 s)
21/12/04 17:30:55 INFO BlockRDD: Removing RDD 226 from persistence list
21/12/04 17:30:55 INFO BlockManager: Removing RDD 226
21/12/04 17:30:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[226] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619255000 ms
21/12/04 17:30:55 INFO ReceivedBlockTracker: Deleting batches: 1638619245000 ms
21/12/04 17:30:55 INFO InputInfoTracker: remove old batch metadata: 1638619245000 ms
21/12/04 17:30:55 INFO BlockManagerInfo: Removed input-0-1638619246800 on 10.0.2.15:40275 in memory (size: 1747.5 KiB, free: 364.7 MiB)
21/12/04 17:31:00 INFO JobScheduler: Added jobs for time 1638619260000 ms
21/12/04 17:31:00 INFO JobScheduler: Starting job streaming job 1638619260000 ms.0 from job set of time 1638619260000 ms
21/12/04 17:31:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:31:00 INFO DAGScheduler: Job 92 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000341 s
21/12/04 17:31:00 INFO JobScheduler: Finished job streaming job 1638619260000 ms.0 from job set of time 1638619260000 ms
21/12/04 17:31:00 INFO JobScheduler: Total delay: 0.096 s for time 1638619260000 ms (execution: 0.089 s)
21/12/04 17:31:00 INFO BlockRDD: Removing RDD 234 from persistence list
21/12/04 17:31:00 INFO BlockManager: Removing RDD 234
21/12/04 17:31:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[234] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619260000 ms
21/12/04 17:31:00 INFO BlockManagerInfo: Removed input-0-1638619251800 on 10.0.2.15:40275 in memory (size: 1592.0 KiB, free: 366.3 MiB)
21/12/04 17:31:00 INFO ReceivedBlockTracker: Deleting batches: 1638619250000 ms
21/12/04 17:31:00 INFO InputInfoTracker: remove old batch metadata: 1638619250000 ms
21/12/04 17:31:02 INFO SocketReceiver: Closed socket to localhost:6100
21/12/04 17:31:02 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Socket data stream had no more data
21/12/04 17:31:02 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Socket data stream had no more data: 
21/12/04 17:31:02 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:02 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:02 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Socket data stream had no more data
21/12/04 17:31:02 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:04 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:04 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:04 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:04 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:04 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:05 INFO JobScheduler: Added jobs for time 1638619265000 ms
21/12/04 17:31:05 INFO JobScheduler: Starting job streaming job 1638619265000 ms.0 from job set of time 1638619265000 ms
21/12/04 17:31:05 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:31:05 INFO DAGScheduler: Job 93 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000286 s
21/12/04 17:31:05 INFO JobScheduler: Finished job streaming job 1638619265000 ms.0 from job set of time 1638619265000 ms
21/12/04 17:31:05 INFO JobScheduler: Total delay: 0.044 s for time 1638619265000 ms (execution: 0.032 s)
21/12/04 17:31:05 INFO BlockRDD: Removing RDD 242 from persistence list
21/12/04 17:31:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[242] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619265000 ms
21/12/04 17:31:05 INFO BlockManager: Removing RDD 242
21/12/04 17:31:05 INFO ReceivedBlockTracker: Deleting batches: 1638619255000 ms
21/12/04 17:31:05 INFO InputInfoTracker: remove old batch metadata: 1638619255000 ms
21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:06 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:06 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:06 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:06 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:06 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:08 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:08 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:08 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:08 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:08 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:10 INFO JobScheduler: Added jobs for time 1638619270000 ms
21/12/04 17:31:10 INFO JobScheduler: Starting job streaming job 1638619270000 ms.0 from job set of time 1638619270000 ms
21/12/04 17:31:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:31:10 INFO DAGScheduler: Job 94 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.003901 s
21/12/04 17:31:10 INFO JobScheduler: Finished job streaming job 1638619270000 ms.0 from job set of time 1638619270000 ms
21/12/04 17:31:10 INFO JobScheduler: Total delay: 0.053 s for time 1638619270000 ms (execution: 0.042 s)
21/12/04 17:31:10 INFO BlockRDD: Removing RDD 243 from persistence list
21/12/04 17:31:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[243] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619270000 ms
21/12/04 17:31:10 INFO ReceivedBlockTracker: Deleting batches: 1638619260000 ms
21/12/04 17:31:10 INFO InputInfoTracker: remove old batch metadata: 1638619260000 ms
21/12/04 17:31:10 INFO BlockManager: Removing RDD 243
21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:10 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:10 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:10 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:10 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:10 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:12 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:12 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:12 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:12 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:14 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:14 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:14 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:14 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:15 INFO JobScheduler: Added jobs for time 1638619275000 ms
21/12/04 17:31:15 INFO JobScheduler: Starting job streaming job 1638619275000 ms.0 from job set of time 1638619275000 ms
21/12/04 17:31:15 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:31:15 INFO DAGScheduler: Job 95 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000329 s
21/12/04 17:31:15 INFO JobScheduler: Finished job streaming job 1638619275000 ms.0 from job set of time 1638619275000 ms
21/12/04 17:31:15 INFO JobScheduler: Total delay: 0.031 s for time 1638619275000 ms (execution: 0.025 s)
21/12/04 17:31:15 INFO BlockRDD: Removing RDD 244 from persistence list
21/12/04 17:31:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[244] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619275000 ms
21/12/04 17:31:15 INFO BlockManager: Removing RDD 244
21/12/04 17:31:15 INFO ReceivedBlockTracker: Deleting batches: 1638619265000 ms
21/12/04 17:31:15 INFO InputInfoTracker: remove old batch metadata: 1638619265000 ms
21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:16 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:16 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:16 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:16 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:18 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:18 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:18 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:18 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:20 INFO JobScheduler: Added jobs for time 1638619280000 ms
21/12/04 17:31:20 INFO JobScheduler: Starting job streaming job 1638619280000 ms.0 from job set of time 1638619280000 ms
21/12/04 17:31:20 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:31:20 INFO DAGScheduler: Job 96 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000198 s
21/12/04 17:31:20 INFO JobScheduler: Finished job streaming job 1638619280000 ms.0 from job set of time 1638619280000 ms
21/12/04 17:31:20 INFO JobScheduler: Total delay: 0.020 s for time 1638619280000 ms (execution: 0.017 s)
21/12/04 17:31:20 INFO BlockRDD: Removing RDD 245 from persistence list
21/12/04 17:31:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[245] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619280000 ms
21/12/04 17:31:20 INFO ReceivedBlockTracker: Deleting batches: 1638619270000 ms
21/12/04 17:31:20 INFO InputInfoTracker: remove old batch metadata: 1638619270000 ms
21/12/04 17:31:20 INFO BlockManager: Removing RDD 245
21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:20 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:20 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:20 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:20 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:22 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:22 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:22 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:22 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:24 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:24 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:24 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:24 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:25 INFO JobScheduler: Added jobs for time 1638619285000 ms
21/12/04 17:31:25 INFO JobScheduler: Starting job streaming job 1638619285000 ms.0 from job set of time 1638619285000 ms
21/12/04 17:31:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:31:25 INFO DAGScheduler: Job 97 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000242 s
21/12/04 17:31:25 INFO JobScheduler: Finished job streaming job 1638619285000 ms.0 from job set of time 1638619285000 ms
21/12/04 17:31:25 INFO JobScheduler: Total delay: 0.032 s for time 1638619285000 ms (execution: 0.025 s)
21/12/04 17:31:25 INFO BlockRDD: Removing RDD 246 from persistence list
21/12/04 17:31:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[246] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619285000 ms
21/12/04 17:31:25 INFO ReceivedBlockTracker: Deleting batches: 1638619275000 ms
21/12/04 17:31:25 INFO BlockManager: Removing RDD 246
21/12/04 17:31:25 INFO InputInfoTracker: remove old batch metadata: 1638619275000 ms
21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:26 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:26 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:26 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:26 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:28 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:28 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:28 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:28 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:30 INFO JobScheduler: Added jobs for time 1638619290000 ms
21/12/04 17:31:30 INFO JobScheduler: Starting job streaming job 1638619290000 ms.0 from job set of time 1638619290000 ms
21/12/04 17:31:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/04 17:31:30 INFO DAGScheduler: Job 98 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.002341 s
21/12/04 17:31:30 INFO JobScheduler: Finished job streaming job 1638619290000 ms.0 from job set of time 1638619290000 ms
21/12/04 17:31:30 INFO JobScheduler: Total delay: 0.064 s for time 1638619290000 ms (execution: 0.060 s)
21/12/04 17:31:30 INFO BlockRDD: Removing RDD 247 from persistence list
21/12/04 17:31:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[247] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638619290000 ms
21/12/04 17:31:30 INFO ReceivedBlockTracker: Deleting batches: 1638619280000 ms
21/12/04 17:31:30 INFO InputInfoTracker: remove old batch metadata: 1638619280000 ms
21/12/04 17:31:30 INFO BlockManager: Removing RDD 247
21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:30 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:30 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:30 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:30 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:32 INFO ReceiverTracker: Registered receiver for stream 0 from 10.0.2.15:33623
21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/04 17:31:32 INFO SocketReceiver: Connecting to localhost:6100
21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:32 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/04 17:31:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:229)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/12/04 17:31:32 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/04 17:31:34 INFO TaskSchedulerImpl: Cancelling stage 0
21/12/04 17:31:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled
21/12/04 17:31:34 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled
21/12/04 17:31:34 INFO TaskSchedulerImpl: Stage 0 was cancelled
21/12/04 17:31:34 INFO DAGScheduler: ResultStage 0 (start at NativeMethodAccessorImpl.java:0) failed in 189.354 s due to Job 0 cancelled as part of cancellation of all jobs
21/12/04 17:31:34 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job 0 cancelled as part of cancellation of all jobs
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2154)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$doCancelAllJobs$2(DAGScheduler.scala:972)
	at scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:971)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2410)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
21/12/04 17:31:34 INFO ReceiverTracker: Restarting Receiver 0
21/12/04 17:31:34 INFO StreamingContext: Invoking stop(stopGracefully=false) from shutdown hook
21/12/04 17:31:34 INFO ReceiverTracker: Receiver 0 started
21/12/04 17:31:34 INFO DAGScheduler: Got job 99 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/04 17:31:34 INFO DAGScheduler: Final stage: ResultStage 91 (start at NativeMethodAccessorImpl.java:0)
21/12/04 17:31:34 INFO DAGScheduler: Parents of final stage: List()
21/12/04 17:31:34 INFO DAGScheduler: Missing parents: List()
21/12/04 17:31:34 INFO DAGScheduler: Submitting ResultStage 91 (Receiver 0 ParallelCollectionRDD[249] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
21/12/04 17:31:34 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/04 17:31:34 INFO ReceiverSupervisorImpl: Stopping receiver with message: Registered unsuccessfully because Driver refused to start receiver 0: 
21/12/04 17:31:34 WARN ReceiverSupervisorImpl: Receiver has been stopped
21/12/04 17:31:34 INFO BlockGenerator: Stopping BlockGenerator
21/12/04 17:31:34 INFO ReceiverSupervisorImpl: Received stop signal
21/12/04 17:31:34 INFO ReceiverTracker: Sent stop signal to all 1 receivers
21/12/04 17:31:34 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 81.5 KiB, free 366.1 MiB)
21/12/04 17:31:34 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 366.1 MiB)
21/12/04 17:31:34 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.0.2.15:40275 (size: 28.5 KiB, free: 366.2 MiB)
21/12/04 17:31:34 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1388
21/12/04 17:31:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (Receiver 0 ParallelCollectionRDD[249] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
21/12/04 17:31:34 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
21/12/04 17:31:34 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 91) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 5478 bytes) taskResourceAssignments Map()
21/12/04 17:31:34 ERROR Inbox: Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@179b6490 rejected from java.util.concurrent.ThreadPoolExecutor@36055e5b[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 90]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:270)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:68)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/12/04 17:31:34 INFO SparkUI: Stopped Spark web UI at http://10.0.2.15:4040
21/12/04 17:31:34 INFO ReceiverTracker: All of the receivers have deregistered successfully
21/12/04 17:31:34 INFO DAGScheduler: ResultStage 91 (start at NativeMethodAccessorImpl.java:0) failed in 0.158 s due to Stage cancelled because SparkContext was shut down
21/12/04 17:31:34 INFO ReceiverTracker: ReceiverTracker stopped
21/12/04 17:31:34 INFO JobGenerator: Stopping JobGenerator immediately
21/12/04 17:31:34 INFO RecurringTimer: Stopped timer for JobGenerator after time 1638619290000
21/12/04 17:31:34 INFO JobGenerator: Stopped JobGenerator
21/12/04 17:31:34 INFO JobScheduler: Stopped JobScheduler
21/12/04 17:31:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/12/04 17:31:34 INFO RecurringTimer: Stopped timer for BlockGenerator after time 1638619294600
21/12/04 17:31:34 INFO BlockGenerator: Waiting for block pushing thread to terminate
21/12/04 17:31:34 INFO BlockGenerator: Pushing out the last 0 blocks
21/12/04 17:31:34 INFO BlockGenerator: Stopped block pushing thread
21/12/04 17:31:34 INFO BlockGenerator: Stopped BlockGenerator
21/12/04 17:31:34 INFO ReceiverSupervisorImpl: Receiver started again
21/12/04 17:31:34 INFO ReceiverSupervisorImpl: Stopping receiver with message: Stopped by driver: 
21/12/04 17:31:34 WARN ReceiverSupervisorImpl: Receiver has been stopped
21/12/04 17:31:34 INFO ReceiverSupervisorImpl: Stopped receiver without error
21/12/04 17:31:34 WARN BlockGenerator: Cannot stop BlockGenerator as its not in the Active state [state = StoppedAll]
21/12/04 17:31:34 INFO Executor: Executor killed task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled
21/12/04 17:31:34 INFO StreamingContext: StreamingContext stopped successfully
21/12/04 17:31:34 INFO ShutdownHookManager: Shutdown hook called
21/12/04 17:31:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-de5180f9-f6aa-454e-abf3-6d0253a1f8d7
21/12/04 17:31:34 INFO MemoryStore: MemoryStore cleared
21/12/04 17:31:34 INFO BlockManager: BlockManager stopped
21/12/04 17:31:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-7644769f-04cc-4cb1-b93c-579c4a5fe847/pyspark-1d06c937-d5fc-44eb-9c32-91eb22a43058
21/12/04 17:31:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-7644769f-04cc-4cb1-b93c-579c4a5fe847
21/12/04 17:31:34 INFO BlockManagerMaster: BlockManagerMaster stopped
21/12/04 17:31:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/12/04 17:31:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-7644769f-04cc-4cb1-b93c-579c4a5fe847/userFiles-6c0237ec-f993-4561-be75-cfcedb7eadb3
